# Concept Schema v5 - Complete Documentation

## Overview

This document provides exhaustive documentation for the 9-dimensional concept analysis schema. It explains:
- The philosophical grounding of each dimension
- What each table and field captures
- Where values come from (source types)
- How dimensions interrelate
- The workflow for populating and testing concepts

---

## Table of Contents

1. [Schema Philosophy](#1-schema-philosophy)
2. [Source Types and Data Provenance](#2-source-types-and-data-provenance)
3. [Core Concept Record](#3-core-concept-record)
4. [Dimension 1: Quinean](#4-dimension-1-quinean)
5. [Dimension 2: Sellarsian](#5-dimension-2-sellarsian)
6. [Dimension 3: Brandomian](#6-dimension-3-brandomian)
7. [Dimension 4: Deleuzian](#7-dimension-4-deleuzian)
8. [Dimension 5: Bachelardian](#8-dimension-5-bachelardian)
9. [Dimension 6: Canguilhem](#9-dimension-6-canguilhem)
10. [Dimension 7: Hacking](#10-dimension-7-hacking)
11. [Dimension 8: Blumenberg](#11-dimension-8-blumenberg)
12. [Dimension 9: Carey](#12-dimension-9-carey)
13. [Cross-Dimensional Analysis](#13-cross-dimensional-analysis)
14. [Feedback System](#14-feedback-system)
15. [Workflow Summary](#15-workflow-summary)

---

## 1. Schema Philosophy

### Why Nine Dimensions?

Traditional concept analysis treats concepts as static definitions. This schema treats concepts as **living theoretical entities** that can be analyzed from multiple philosophical perspectives, each revealing different aspects:

| Dimension | Core Question | What It Reveals |
|-----------|--------------|-----------------|
| Quinean | How does this concept connect to other beliefs? | Web position, revisability, dependencies |
| Sellarsian | What does this concept presuppose without justification? | Hidden assumptions, false foundations |
| Brandomian | What commitments does using this concept involve? | Inferential obligations, entitlements |
| Deleuzian | What are the internal components of this concept? | Multiplicity structure, consistency |
| Bachelardian | How does this concept block understanding? | Epistemological obstacles, stages |
| Canguilhem | What is this concept's life history? | Evolution, health, vitality |
| Hacking | How does this concept create what it describes? | Looping effects, kinds created |
| Blumenberg | What metaphors structure this concept? | Root metaphors, nonconceptual elements |
| Carey | How was this concept bootstrapped from simpler ones? | Hierarchy, placeholders, constraints |

### Modular Architecture

Every value in every table is:
1. **Individually addressable** - Can be tested, revised, or challenged separately
2. **Source-tracked** - We know where each value came from
3. **Confidence-scored** - We know how certain we are
4. **Testable** - Evidence clusters can challenge any specific value

This modularity enables:
- Precise identification of what evidence challenges
- Targeted revisions without wholesale concept replacement
- Audit trails for conceptual evolution
- Multi-source triangulation

---

## 2. Source Types and Data Provenance

Every table includes three tracking fields:

```
source_type     VARCHAR(30)   -- Where this value came from
source_reference TEXT         -- Specific source identifier
confidence      FLOAT         -- 0.0 to 1.0 confidence score
```

### Source Type Taxonomy

#### `user_input`
**What it is:** Values entered directly by users during concept setup or revision.

**When it occurs:**
- Initial concept creation via Q&A wizard
- Manual edits by domain experts
- User corrections to LLM-generated values

**Confidence:** Typically 1.0 (user is authoritative) unless user indicates uncertainty

**Example source_reference:** `initial_import`, `user_edit_2024_03_15`, `expert_review_jones`

---

#### `llm_analysis`
**What it is:** Values generated by LLM analysis of the concept.

**When it occurs:**
- Initial concept elaboration (LLM expands user-provided definition)
- Dimension-specific analysis (LLM applies Quinean lens, etc.)
- Periodic re-analysis as schema evolves

**Confidence:** Varies by task complexity (0.6-0.9 typical)

**Example source_reference:** `claude-opus-4-20250514`, `quine_analysis_v2`, `brandom_elaboration_batch_7`

---

#### `evidence_testing`
**What it is:** Values derived from testing concept against evidence clusters.

**When it occurs:**
- Essay-flow evidence clusters test concept values
- Research documents analyzed against concept
- Empirical case studies evaluated

**Confidence:** Based on evidence strength and cluster consensus

**Example source_reference:** `cluster_42`, `evidence_batch_2024_03`, `project_2_clusters`

---

#### `internal_compute`
**What it is:** Values computed from other values in the database.

**When it occurs:**
- Entrenchment scores computed from inference counts
- Health status derived from vitality indicators
- Cross-reference consistency checks

**Confidence:** Depends on input value confidence

**Example source_reference:** `entrenchment_calc_v2`, `health_aggregation`, `consistency_check_run_45`

---

#### `import`
**What it is:** Values imported from external sources (papers, databases, ontologies).

**When it occurs:**
- Bulk import from existing concept databases
- Integration with external knowledge bases
- Migration from legacy systems

**Confidence:** Inherited from source, typically requires validation

**Example source_reference:** `stanford_encyclopedia_import`, `wikidata_Q12345`, `legacy_db_migration`

---

### Confidence Scoring Guidelines

| Score | Meaning | Typical Source |
|-------|---------|----------------|
| 0.95-1.0 | Near certain | User input, multiple confirming sources |
| 0.85-0.94 | High confidence | Strong LLM analysis, clear evidence |
| 0.70-0.84 | Moderate confidence | Single LLM analysis, mixed evidence |
| 0.50-0.69 | Low confidence | Uncertain inference, weak evidence |
| <0.50 | Very uncertain | Speculative, requires validation |

---

## 3. Core Concept Record

### Table: `concepts`

The master record for each concept. All dimension tables reference this via `concept_id`.

| Field | Type | Description | Source |
|-------|------|-------------|--------|
| `id` | SERIAL | Primary key | system |
| `name` | VARCHAR(300) | Concept name | user_input |
| `definition` | TEXT | Core definition | user_input, refined by llm_analysis |
| `domain` | VARCHAR(100) | Primary domain (IR, Philosophy, etc.) | user_input |
| `first_appearance` | TEXT | When concept emerged historically | llm_analysis |
| `current_usage_frequency` | VARCHAR(50) | How often used now | evidence_testing |
| `centrality` | VARCHAR(30) | core/intermediate/peripheral | llm_analysis |
| `entrenchment_score` | FLOAT | How resistant to revision (0-1) | internal_compute |
| `health_status` | VARCHAR(30) | healthy/strained/declining/transforming | internal_compute |
| `hierarchy_level` | INTEGER | Carey hierarchy (1-4) | llm_analysis |
| `created_at` | TIMESTAMPTZ | Creation timestamp | system |
| `updated_at` | TIMESTAMPTZ | Last update | system |

### Field Explanations

**`centrality`**: Quinean concept - how central is this to the overall belief web?
- `core`: Revising this would ripple through many other concepts
- `intermediate`: Connected to several concepts but not foundational
- `peripheral`: Can be revised with minimal impact on other beliefs

**`entrenchment_score`**: Computed value (0-1) indicating resistance to revision
- Based on: number of inferences, centrality, usage frequency, institutional embedding
- Higher = harder to revise without major consequences

**`health_status`**: Canguilhem concept - the "vital" status of the concept
- `healthy`: Coherent, productive, well-supported
- `strained`: Internal tensions emerging, some challenges unanswered
- `declining`: Losing coherence, evidence mounting against
- `transforming`: Undergoing significant conceptual change

**`hierarchy_level`**: Carey concept - bootstrapping complexity
- Level 1: Primitive (directly grounded in experience/core cognition)
- Level 2: Simple composite (combines Level 1 concepts)
- Level 3: Complex composite (combines Level 2 concepts)
- Level 4: Theoretical (highly abstract, far from experience)

---

## 4. Dimension 1: Quinean

### Philosophical Background

**Source:** W.V.O. Quine, "Two Dogmas of Empiricism" (1951); "Word and Object" (1960)

**Core Ideas:**
- **Confirmation Holism**: Beliefs face experience as a corporate body, not individually
- **No Analytic/Synthetic Distinction**: No beliefs are immune to revision
- **Web of Belief**: Concepts connected by inferential relations form a web
- **Ontological Relativity**: What exists is relative to a conceptual scheme
- **Pragmatic Revisability**: We revise beliefs to maximize overall coherence/utility

**What This Dimension Captures:**
How the concept is positioned in the web of belief - its inferential connections, tensions with other concepts, and the consequences of revising it.

---

### Table: `concept_inferences`

Maps the inferential connections from/to this concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `from_concept` | VARCHAR(200) | Source concept (can be this concept or another) |
| `to_concept` | VARCHAR(200) | Target concept |
| `inference_type` | VARCHAR(30) | committive/permissive/incompatibility/enabling |
| `strength` | VARCHAR(20) | strong/moderate/weak |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Inference Types:**
- `committive`: If you accept A, you're committed to B (A → committed to B)
- `permissive`: If you accept A, you're entitled to B (A → entitled to B)
- `incompatibility`: A and B cannot both be true (A → ¬B)
- `enabling`: A is a precondition for B (A enables B)

**Source:**
- Initial: `llm_analysis` (LLM identifies obvious inferences from definition)
- Refinement: `evidence_testing` (evidence reveals inferences we missed or got wrong)
- Correction: `user_input` (domain expert corrects)

**Example:**
```
from_concept: "technological sovereignty"
to_concept: "indigenous capability"
inference_type: committive
strength: strong
source_type: llm_analysis
confidence: 0.85
```
*Interpretation: If you claim tech sovereignty, you're committed to developing indigenous capability.*

---

### Table: `concept_web_tensions`

Captures tensions/contradictions between concepts in the web.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `concept_a` | VARCHAR(200) | First concept in tension |
| `concept_b` | VARCHAR(200) | Second concept in tension |
| `tension_type` | VARCHAR(30) | practical_contradiction/tradeoff/structural |
| `description` | TEXT | What the tension is |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Tension Types:**
- `practical_contradiction`: Cannot pursue both simultaneously in practice
- `tradeoff`: Must sacrifice some of one to gain the other
- `structural`: Deeper incompatibility in how concepts are constituted

**Source:**
- Initial: `llm_analysis` (LLM identifies tensions from concept structure)
- Discovery: `evidence_testing` (evidence reveals tensions in practice)

**Example:**
```
concept_a: "tech sovereignty"
concept_b: "global supply chains"
tension_type: practical_contradiction
description: "Pursuing sovereignty while depending on global semiconductor supply chains"
source_type: evidence_testing
source_reference: cluster_89
confidence: 0.92
```

---

### Table: `concept_web_position`

Identifies the concept's structural position in the belief web.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `position_type` | VARCHAR(30) | hub/bridge/leaf/foundation |
| `connected_concepts` | TEXT | List of connected concepts |
| `bridging_function` | TEXT | What domains/clusters it bridges |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Position Types:**
- `hub`: Many connections, central to a domain
- `bridge`: Connects otherwise separate conceptual clusters
- `leaf`: Few connections, at periphery
- `foundation`: Supports many other concepts, rarely questioned

**Source:**
- Computed: `internal_compute` (from inference counts and network analysis)
- Refined: `llm_analysis` (qualitative assessment of bridging function)

**Example:**
```
position_type: hub
connected_concepts: "national security, industrial policy, digital rights, trade policy"
bridging_function: "Central node connecting security and economic policy domains"
```

---

### Table: `concept_ontological_dependence`

Captures what entities/concepts this concept presupposes (Quine's ontological relativity).

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `depends_on` | VARCHAR(200) | What it depends on |
| `dependence_type` | VARCHAR(30) | existential/definitional/relational |
| `explanation` | TEXT | How the dependence works |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Dependence Types:**
- `existential`: Concept presupposes existence of this entity
- `definitional`: Definition requires reference to this concept
- `relational`: Only meaningful in relation to this

**Source:**
- Initial: `llm_analysis` (LLM identifies ontological presuppositions)
- Discovery: `evidence_testing` (evidence reveals hidden dependencies)

**Example:**
```
depends_on: "the state"
dependence_type: existential
explanation: "Concept presupposes existence of state actors capable of sovereign action"
```
*Interpretation: Tech sovereignty makes no sense without states as actors - it has an existential dependence on "the state" as an entity.*

---

### Table: `concept_revision_ramifications`

Models what happens if this concept is revised or abandoned (Quine's pragmatic revisability).

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `if_revised` | VARCHAR(50) | Type of revision (abandoned/weakened/split/etc.) |
| `affected_concepts` | TEXT | What else would need to change |
| `revision_cost` | VARCHAR(20) | very_high/high/moderate/low |
| `pragmatic_consideration` | TEXT | Practical implications |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM traces revision implications)
- Evidence: `evidence_testing` (evidence suggests specific revision paths)

**Example:**
```
if_revised: abandoned
affected_concepts: "industrial_policy, national_security_framing, EU_strategic_autonomy"
revision_cost: very_high
pragmatic_consideration: "Would require reworking entire policy frameworks in EU, China, India"
```

---

## 5. Dimension 2: Sellarsian

### Philosophical Background

**Source:** Wilfrid Sellars, "Empiricism and the Philosophy of Mind" (1956); "Science and Metaphysics" (1968)

**Core Ideas:**
- **Myth of the Given**: Nothing is simply "given" to consciousness without conceptual mediation
- **Space of Reasons**: Concepts get meaning from their role in justification/inference
- **Functional Role Semantics**: Meaning = inferential role in the conceptual network
- **Manifest vs. Scientific Image**: Tension between everyday and scientific pictures of the world

**What This Dimension Captures:**
What the concept treats as foundational/obvious that is actually inferred, what hidden assumptions it carries, and how it functions in the space of reasons.

---

### Table: `concept_givenness`

Identifies what the concept treats as "given" (self-evident, foundational) that actually isn't.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `given_claim` | TEXT | What's treated as given |
| `givenness_level` | VARCHAR(20) | high/moderate/low |
| `actual_basis` | TEXT | What it's actually inferred from |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Givenness Levels:**
- `high`: Treated as completely self-evident, never questioned
- `moderate`: Sometimes questioned but usually assumed
- `low`: Occasionally treated as given

**Source:**
- Initial: `llm_analysis` (LLM identifies false givens from concept usage)
- Discovery: `evidence_testing` (evidence exposes what's actually being assumed)

**Example:**
```
given_claim: "States can achieve technological autonomy"
givenness_level: high
actual_basis: "Inferred from contested premises about state capacity and market dynamics"
```
*Interpretation: The claim that states CAN achieve tech autonomy is treated as obvious, but it's actually based on debatable assumptions.*

---

### Table: `concept_hidden_commitments`

Exposes assumptions baked into the concept that users may not realize they're making.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `commitment` | TEXT | The hidden assumption |
| `how_hidden` | TEXT | Why it's not obvious |
| `implications` | TEXT | What following this assumption leads to |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM uncovers embedded assumptions)
- Discovery: `evidence_testing` (evidence reveals assumptions we missed)

**Example:**
```
commitment: "Technology development is linear and predictable"
how_hidden: "Embedded in 'roadmap' rhetoric"
implications: "Blinds to disruptive innovation from unexpected sources"
```

---

### Table: `concept_space_of_reasons`

Maps how the concept functions in justificatory discourse.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `inferential_role` | VARCHAR(50) | premise_for_X/conclusion_from_X/legitimation_device |
| `justificatory_relations` | TEXT | What it justifies or is justified by |
| `normative_status` | TEXT | How accepted is this role |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM analyzes discursive function)
- Evidence: `evidence_testing` (evidence shows how concept actually functions)

**Example:**
```
inferential_role: premise_for_industrial_policy
justificatory_relations: "Justifies subsidies, tariffs, procurement preferences"
normative_status: "Widely accepted in policy circles"
```

---

### Table: `concept_functional_role`

Specifies the concept's role in different discursive contexts (Sellars' functional role semantics).

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `role_type` | VARCHAR(50) | enabling_premise/framing_device/mobilization_rhetoric/etc. |
| `in_discourse` | VARCHAR(100) | Which discourse context |
| `inferential_connections` | TEXT | What inferences it enables |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies functional roles)
- Evidence: `evidence_testing` (evidence shows actual usage patterns)

**Example:**
```
role_type: enabling_premise
in_discourse: "Policy debates"
inferential_connections: "Enables conclusions about state intervention legitimacy"
```

---

### Table: `concept_image_tension`

Captures tension between manifest (everyday) and scientific understandings.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `manifest_image` | TEXT | Everyday/common understanding |
| `scientific_image` | TEXT | Expert/technical understanding |
| `tension_description` | TEXT | How they conflict |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies image gap)
- Evidence: `evidence_testing` (evidence shows divergence in practice)

**Example:**
```
manifest_image: "Nation controls its technological destiny"
scientific_image: "Complex global interdependencies make full autonomy impossible"
tension_description: "Manifest image persists despite scientific understanding"
```

---

## 6. Dimension 3: Brandomian

### Philosophical Background

**Source:** Robert Brandom, "Making It Explicit" (1994); "Articulating Reasons" (2000)

**Core Ideas:**
- **Inferentialism**: Meaning is constituted by inferential role, not reference
- **Deontic Scorekeeping**: Using concepts involves tracking commitments and entitlements
- **Game of Giving and Asking for Reasons**: Discourse is a practice of challenging and justifying claims
- **De Dicto vs. De Re**: Difference between what someone says and how we translate it

**What This Dimension Captures:**
What commitments using this concept involves, what challenges it faces, and how different perspectives interpret it.

---

### Table: `concept_commitments`

Tracks the deontic status of commitments associated with the concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `commitment` | TEXT | The commitment claim |
| `deontic_status` | VARCHAR(30) | acknowledged/undertaken/attributed |
| `undertaken_by` | TEXT | Who undertakes this commitment |
| `attributed_by` | TEXT | Who attributes it to others |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Deontic Status:**
- `acknowledged`: Actor explicitly accepts this commitment
- `undertaken`: Actor's actions commit them (whether they acknowledge or not)
- `attributed`: Others attribute this commitment to the actor

**Source:**
- Initial: `llm_analysis` (LLM identifies commitments from concept structure)
- Evidence: `evidence_testing` (evidence shows who actually commits to what)

**Example:**
```
commitment: "Investment leads to capability"
deontic_status: acknowledged
undertaken_by: "EU, China, India"
attributed_by: "Policy analysts"
```

---

### Table: `concept_inferential_roles`

Maps the material inferences the concept licenses.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `inference_type` | VARCHAR(30) | committive/permissive/incompatibility |
| `from_claim` | TEXT | Premise |
| `to_claim` | TEXT | Conclusion |
| `status` | VARCHAR(20) | active/contested/defeated |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Inference Types (Brandom's taxonomy):**
- `committive`: Commitment to A commits you to B
- `permissive`: Commitment to A entitles you to B
- `incompatibility`: Commitment to A precludes commitment to B

**Status:**
- `active`: Inference is generally accepted
- `contested`: Inference is debated
- `defeated`: Counterexamples have undermined the inference

**Source:**
- Initial: `llm_analysis` (LLM identifies inferences)
- Testing: `evidence_testing` (evidence challenges or confirms inferences)

**Example:**
```
inference_type: incompatibility
from_claim: "X has tech sovereignty"
to_claim: "X depends on adversary supply chains"
status: logical
```

---

### Table: `concept_perspectival_content`

Captures how different speakers understand the concept differently (de dicto vs. de re).

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `speaker_perspective` | VARCHAR(100) | Whose perspective |
| `de_dicto_content` | TEXT | What they say (in their terms) |
| `de_re_translation` | TEXT | Our translation (what we think they mean) |
| `translation_loss` | TEXT | What's lost in translation |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies perspectival differences)
- Evidence: `evidence_testing` (evidence from different actor documents)

**Example:**
```
speaker_perspective: "Gulf states"
de_dicto_content: "Technological sovereignty through investment"
de_re_translation: "Technology consumption + influence via capital"
translation_loss: "Loses self-reliance claim entirely"
```
*Interpretation: When Gulf states say "tech sovereignty," they mean something quite different from what China means - our translation reveals this.*

---

### Table: `concept_challenges`

Tracks challenges to commitments and whether they've been answered.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `challenge` | TEXT | The challenging evidence/argument |
| `to_commitment` | TEXT | Which commitment is challenged |
| `challenger` | TEXT | Source of challenge |
| `response_status` | VARCHAR(30) | unanswered/partially_addressed/addressed/acknowledged |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Response Status:**
- `unanswered`: No response to the challenge
- `partially_addressed`: Some response but not fully satisfying
- `addressed`: Challenge has been answered
- `acknowledged`: Challenge accepted as limitation

**Source:**
- Discovery: `evidence_testing` (evidence clusters reveal challenges)
- Analysis: `llm_analysis` (LLM identifies logical challenges)

**Example:**
```
challenge: "Gulf states have $2T but can't do Series B"
to_commitment: "Investment leads to capability"
challenger: "Empirical evidence"
response_status: unanswered
```
*Interpretation: This is a direct challenge to a core commitment of the concept - and it hasn't been answered.*

---

## 7. Dimension 4: Deleuzian

### Philosophical Background

**Source:** Gilles Deleuze & Félix Guattari, "What is Philosophy?" (1991)

**Core Ideas:**
- **Concepts as Multiplicities**: Concepts are not unitary but composed of distinct components
- **Zones of Indiscernibility**: Where components overlap/blur into each other
- **Endoconsistency/Exoconsistency**: Internal coherence and external relations
- **Plane of Immanence**: The pre-philosophical background that makes concepts thinkable
- **Conceptual Personae**: The "characters" that activate and deploy concepts

**What This Dimension Captures:**
The internal structure of the concept - its components, how they hold together, what plane it operates on, and who deploys it.

---

### Table: `concept_components`

Identifies the distinct components that make up the concept's multiplicity.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `component` | VARCHAR(100) | Component name |
| `description` | TEXT | What this component contributes |
| `ordering` | VARCHAR(30) | intensive/extensive |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Ordering:**
- `intensive`: Qualitative, non-divisible (like temperature)
- `extensive`: Quantitative, additive (like volume)

**Source:**
- Initial: `llm_analysis` (LLM identifies components from definition)
- Refinement: `evidence_testing` (evidence reveals components we missed)

**Example:**
```
component: "temporality"
description: "Urgency - limited window before lock-in"
ordering: intensive
```

---

### Table: `concept_zones_of_indiscernibility`

Maps where components blur into each other, creating productive tensions.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `component_a` | VARCHAR(100) | First component |
| `component_b` | VARCHAR(100) | Second component |
| `zone_character` | VARCHAR(30) | overlapping/contested/paradoxical/temporal |
| `productive_tension` | TEXT | What the zone produces |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Zone Characters:**
- `overlapping`: Components share territory
- `contested`: Components compete for same conceptual space
- `paradoxical`: Components require and undermine each other
- `temporal`: Zone shifts over time

**Source:**
- Initial: `llm_analysis` (LLM identifies zones from component analysis)
- Evidence: `evidence_testing` (evidence shows how zones function)

**Example:**
```
component_a: "autonomy"
component_b: "innovation"
zone_character: paradoxical
productive_tension: "Autonomy may require openness that undermines it"
```

---

### Table: `concept_consistency`

Assesses the concept's internal and external coherence.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `consistency_type` | VARCHAR(30) | endoconsistency/exoconsistency |
| `level` | VARCHAR(30) | strong/moderate/unstable/fragmenting |
| `assessment` | TEXT | Explanation |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Consistency Types:**
- `endoconsistency`: How well components hold together internally
- `exoconsistency`: How well concept connects to neighboring concepts

**Source:**
- Computed: `internal_compute` (from component and zone analysis)
- Refined: `llm_analysis` (qualitative assessment)

---

### Table: `concept_plane_of_immanence`

Identifies the pre-philosophical plane on which the concept operates.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `plane` | VARCHAR(100) | Name of the plane |
| `characteristics` | TEXT | What defines this plane |
| `presuppositions` | TEXT | What the plane takes for granted |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies underlying plane)
- Evidence: `evidence_testing` (evidence shows plane in action)

**Example:**
```
plane: "techno-nationalist"
characteristics: "Competition between state-civilization blocs; technology as power; zero-sum framing"
presuppositions: "States are primary actors; technology is controllable; competition is inevitable"
```
*Interpretation: The concept only makes sense within a worldview where states compete and technology is power.*

---

### Table: `concept_personae`

Identifies the conceptual personae that activate and deploy the concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `persona` | VARCHAR(100) | Name of the persona |
| `role` | TEXT | How this persona activates the concept |
| `voice_characteristics` | TEXT | How this persona speaks |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies typical deployers)
- Evidence: `evidence_testing` (evidence shows actual usage patterns)

**Example:**
```
persona: "The Securitizer"
role: "Activates through threat construction"
voice_characteristics: "Urgent, existential risk framing"
```

---

## 8. Dimension 5: Bachelardian

### Philosophical Background

**Source:** Gaston Bachelard, "The Formation of the Scientific Mind" (1938); "The New Scientific Spirit" (1934)

**Core Ideas:**
- **Epistemological Obstacles**: Concepts can block rather than enable understanding
- **Obstacle Taxonomy**: Verbal, substantialist, animist, first experience, quantitative, unitary pragmatism
- **Three Stages**: Pre-scientific, proto-scientific, scientific mind
- **Psychoanalysis of Knowledge**: Concepts serve unconscious needs
- **Regional Rationalism**: Different domains require different rationalities

**What This Dimension Captures:**
How the concept functions as an obstacle to understanding, what stage of thinking it represents, and what unconscious needs it serves.

---

### Table: `concept_obstacles`

Identifies how the concept blocks understanding.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `obstacle_type` | VARCHAR(50) | verbal/substantialist/animist/first_experience/quantitative/unitary_pragmatism |
| `description` | TEXT | How the obstacle functions |
| `entrenchment` | VARCHAR(20) | very_high/high/moderate/low |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Obstacle Types (Bachelard's taxonomy):**
- `verbal`: Word carries inappropriate associations
- `substantialist`: Treating relational properties as substances
- `animist`: Attributing life/agency to non-living things
- `first_experience`: Over-reliance on immediate intuition
- `quantitative`: Believing more of X always means more of Y
- `unitary_pragmatism`: Seeking single explanation for diverse phenomena

**Source:**
- Initial: `llm_analysis` (LLM identifies obstacle functions)
- Evidence: `evidence_testing` (evidence shows blocking in practice)

**Example:**
```
obstacle_type: substantialist
description: "Treating tech capability as substance that can be 'possessed' vs. relational capacity"
entrenchment: very_high
```

---

### Table: `concept_cognitive_stage`

Assesses what stage of thinking the concept represents.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `stage` | VARCHAR(30) | pre-scientific/proto-scientific/scientific |
| `indicators` | TEXT | Evidence for this stage assessment |
| `assessment` | TEXT | Where this stage appears |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Stages:**
- `pre-scientific`: Animistic, magical, substantialist thinking
- `proto-scientific`: Some empiricism but still obstacle-laden
- `scientific`: Rigorous, falsifiable, obstacle-aware

**Source:**
- Initial: `llm_analysis` (LLM assesses discourse patterns)
- Evidence: `evidence_testing` (evidence shows stage in practice)

---

### Table: `concept_psychoanalytic_function`

Identifies unconscious needs the concept serves.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `unconscious_need` | VARCHAR(100) | What need is served |
| `how_concept_satisfies` | TEXT | Mechanism of satisfaction |
| `evidence` | TEXT | Evidence for this function |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies psychological functions)
- Evidence: `evidence_testing` (evidence shows needs being served)

**Example:**
```
unconscious_need: "control_fantasy"
how_concept_satisfies: "Provides illusion of mastering uncontrollable technological change"
evidence: "Emphasis on 'strategic control' despite evidence of limited control"
```

---

### Table: `concept_regional_rationality`

Maps which domain of rationality the concept belongs to.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `rationality_domain` | VARCHAR(50) | geopolitical/economic/technological/legal/etc. |
| `applicable_concepts` | TEXT | Related concepts in this domain |
| `methods_privileged` | TEXT | What methods this domain favors |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies rationality domain)
- Evidence: `evidence_testing` (evidence shows domain usage)

---

## 9. Dimension 6: Canguilhem

### Philosophical Background

**Source:** Georges Canguilhem, "The Normal and the Pathological" (1943/1966); "Ideology and Rationality in the History of the Life Sciences" (1977)

**Core Ideas:**
- **Vital Normativity**: Concepts have "health" - they can be vital or declining
- **Concept Filiation**: Concepts have lineages, parents, offspring
- **Milieu**: Concepts exist in environments that shape them
- **Normal vs. Normative**: Distinction between descriptive average and prescriptive ideal

**What This Dimension Captures:**
The life history of the concept - its evolution, health status, lineage, and operating environment.

---

### Table: `concept_evolution`

Traces the historical development of the concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `period` | VARCHAR(50) | Time period |
| `form` | VARCHAR(50) | What form the concept took |
| `key_developments` | TEXT | What happened in this period |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM traces historical development)
- Evidence: `evidence_testing` (historical evidence)
- Import: `import` (from historical databases)

**Example:**
```
period: "1990-2010"
form: dormancy
key_developments: "Globalization consensus; Washington Consensus; WTO; tech as neutral"
```

---

### Table: `concept_filiation`

Maps the concept's lineage - its ancestors and relatives.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `ancestor_concept` | VARCHAR(200) | Related concept |
| `relationship` | VARCHAR(30) | direct/indirect/sibling/child |
| `what_inherited` | TEXT | What was inherited |
| `what_transformed` | TEXT | What changed |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Relationships:**
- `direct`: Parent concept
- `indirect`: Grandparent or earlier
- `sibling`: Parallel development from same source
- `child`: Concept that developed from this one

**Source:**
- Initial: `llm_analysis` (LLM traces conceptual lineages)
- Evidence: `evidence_testing` (historical evidence)

**Example:**
```
ancestor_concept: "Westphalian sovereignty"
relationship: direct
what_inherited: "Territorial framing, state as actor, non-interference norm"
what_transformed: "Applied to intangible flows"
```

---

### Table: `concept_vital_norms`

Identifies the concept's own vital norms - what it "needs" to remain healthy.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `norm` | VARCHAR(100) | The vital norm |
| `function` | TEXT | What this norm does |
| `violation_indicator` | TEXT | How to tell when norm is violated |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies concept's internal norms)
- Evidence: `evidence_testing` (evidence shows violations)

**Example:**
```
norm: "Autonomy preservation"
function: "Core vital norm - concept exists to enable autonomous action"
violation_indicator: "Using 'sovereignty' to justify increased dependency"
```
*Interpretation: If "tech sovereignty" is invoked to justify things that increase dependency, the concept is being used against its own vital norms.*

---

### Table: `concept_milieu`

Characterizes the environment in which the concept operates.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `milieu_type` | VARCHAR(50) | geopolitical/technological/economic/institutional |
| `current_state` | TEXT | Current state of this milieu |
| `trend` | VARCHAR(30) | intensifying/stable/weakening/restructuring/fragmenting |
| `impact_on_concept` | TEXT | How this affects the concept |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM characterizes environment)
- Evidence: `evidence_testing` (evidence shows environmental factors)

---

### Table: `concept_vitality_indicators`

Tracks metrics of the concept's health.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `indicator` | VARCHAR(50) | What's being measured |
| `current_value` | VARCHAR(30) | Current level |
| `trend` | VARCHAR(30) | Direction of change |
| `interpretation` | TEXT | What this means |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Common Indicators:**
- `usage_frequency`: How often the concept is used
- `policy_adoption`: Translation into actual policy
- `internal_coherence`: Consistency of usage
- `empirical_validation`: Success of predictions/claims

**Source:**
- Computed: `internal_compute` (from various metrics)
- Evidence: `evidence_testing` (evidence shows vitality)

---

## 10. Dimension 7: Hacking

### Philosophical Background

**Source:** Ian Hacking, "Historical Ontology" (2002); "The Social Construction of What?" (1999); "Representing and Intervening" (1983)

**Core Ideas:**
- **Dynamic Nominalism**: Categories and the things they categorize evolve together
- **Looping Effects**: Classifications change the behavior of classified things (especially people)
- **Making Up People**: Categories create new kinds of people
- **Styles of Reasoning**: Different epochs/domains have different standards of truth
- **Space of Possibilities**: What's thinkable is historically contingent

**What This Dimension Captures:**
How the concept creates what it describes, what kinds of things it brings into being, and what possibilities it opens or closes.

---

### Table: `concept_reasoning_styles`

Identifies the reasoning styles associated with the concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `style` | VARCHAR(100) | Name of reasoning style |
| `key_features` | TEXT | What characterizes this style |
| `emergence_period` | TEXT | When this style emerged |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies reasoning patterns)
- Evidence: `evidence_testing` (evidence shows styles in use)

**Example:**
```
style: "geopolitical_strategic"
key_features: "Threat assessment, capability gaps, deterrence logic, balance of power"
emergence_period: "Post-WWII, revived 2015+"
```

---

### Table: `concept_looping_effects`

Captures how the concept changes what it classifies.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `loop_description` | TEXT | What the loop is |
| `mechanism` | TEXT | How the loop works |
| `observed_effects` | TEXT | What changes have been observed |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies potential loops)
- Evidence: `evidence_testing` (evidence shows loops in action)

**Example:**
```
loop_description: "Classification creates behavior"
mechanism: "Labeling countries as 'tech sovereign aspirants' changes how they act"
observed_effects: "Countries pursue performative sovereignty to match label"
```
*Interpretation: The concept isn't just describing reality - it's changing it.*

---

### Table: `concept_kinds_created`

Identifies new kinds of things/people the concept brings into being.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `kind_name` | VARCHAR(100) | Name of the kind |
| `kind_type` | VARCHAR(30) | political_entity/artifact_category/person_kind/etc. |
| `how_created` | TEXT | Mechanism of creation |
| `stability` | TEXT | How stable is this kind |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies created kinds)
- Evidence: `evidence_testing` (evidence shows kinds in existence)

**Example:**
```
kind_name: "Tech-sovereign state"
kind_type: political_entity
how_created: "Classification by sovereignty pursuit rather than achievement"
stability: "unstable - criteria contested"
```

---

### Table: `concept_possibility_space`

Maps what the concept makes thinkable/unthinkable.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `possibility` | VARCHAR(200) | What possibility |
| `opened_or_closed` | VARCHAR(20) | opened/closing/closed/threatened |
| `mechanism` | TEXT | How the concept affects this possibility |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies possibility effects)
- Evidence: `evidence_testing` (evidence shows possibilities changing)

**Example:**
```
possibility: "International tech cooperation"
opened_or_closed: closing
mechanism: "Sovereignty framing casts cooperation as dependency/risk"
```

---

## 11. Dimension 8: Blumenberg

### Philosophical Background

**Source:** Hans Blumenberg, "Paradigms for a Metaphorology" (1960); "The Legitimacy of the Modern Age" (1966)

**Core Ideas:**
- **Absolute Metaphors**: Some metaphors cannot be translated into concepts - they're foundational
- **Nonconceptuality (Unbegrifflichkeit)**: Some aspects of understanding resist conceptualization
- **Metakinetics**: Historical transformation of metaphors
- **Lifeworld Background**: Pre-theoretical understanding that enables concepts

**What This Dimension Captures:**
The metaphorical foundations of the concept, what resists conceptualization, and how metaphors have transformed historically.

---

### Table: `concept_metaphors`

Identifies root metaphors structuring the concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `metaphor` | VARCHAR(100) | The metaphor |
| `type` | VARCHAR(30) | spatial/biological/military/architectural/athletic/etc. |
| `structuring_effect` | TEXT | How it shapes understanding |
| `absoluteness` | VARCHAR(50) | How irreplaceable the metaphor is |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Absoluteness Levels:**
- `very high`: Metaphor is irreplaceable - concept collapses without it
- `high`: Hard to think concept without this metaphor
- `moderate`: Metaphor is helpful but alternatives exist
- `low`: Instrumental metaphor, easily replaced

**Source:**
- Initial: `llm_analysis` (LLM identifies root metaphors)
- Evidence: `evidence_testing` (evidence shows metaphor usage)

**Example:**
```
metaphor: "Race/competition"
type: athletic
structuring_effect: "Tech development as zero-sum contest with finish line"
absoluteness: "very high - dominant"
```

---

### Table: `concept_metakinetics`

Tracks how metaphors have transformed over time.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `metaphor` | VARCHAR(100) | Which metaphor |
| `transformation` | TEXT | How it changed |
| `period` | TEXT | When |
| `driver` | TEXT | What caused the change |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM traces metaphor history)
- Evidence: `evidence_testing` (historical evidence)

---

### Table: `concept_nonconceptuality`

Identifies what resists conceptualization.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `nonconceptual_aspect` | TEXT | What resists |
| `why_resists_conceptualization` | TEXT | Why it can't be captured |
| `manifestation` | TEXT | How it shows up |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies nonconceptual elements)
- Evidence: `evidence_testing` (evidence shows what can't be articulated)

**Example:**
```
nonconceptual_aspect: "Feeling of autonomy"
why_resists_conceptualization: "Experiential quality that can't be reduced to policy metrics"
manifestation: "Leaders speak of 'pride' and 'dignity' alongside capability"
```

---

### Table: `concept_lifeworld_connection`

Maps tension between concept and lived experience.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `lifeworld_aspect` | VARCHAR(100) | Which aspect of lived experience |
| `connection_type` | VARCHAR(50) | experiential_contradiction/structural_tension/practical_tension/relational_tension |
| `tension_level` | VARCHAR(20) | very_high/high/moderate/low |
| `description` | TEXT | What the tension is |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies lifeworld tensions)
- Evidence: `evidence_testing` (evidence shows tensions)

**Example:**
```
lifeworld_aspect: "Daily tech dependence"
connection_type: experiential_contradiction
tension_level: high
description: "People use foreign tech daily while supporting sovereignty rhetoric"
```

---

## 12. Dimension 9: Carey

### Philosophical Background

**Source:** Susan Carey, "The Origin of Concepts" (2009)

**Core Ideas:**
- **Core Cognition**: Innate cognitive systems (object, number, agency, etc.)
- **Quinian Bootstrapping**: Building complex concepts from simpler ones through analogy and combination
- **Placeholder Structures**: Partial concepts awaiting elaboration
- **Conceptual Discontinuity**: New concepts can be genuinely incommensurable with predecessors
- **Computational Constraints**: Cognitive limitations affect what concepts are learnable

**What This Dimension Captures:**
How the concept was built up from simpler components, what cognitive resources it engages, and what constraints affect its learnability.

---

### Table: `concept_hierarchy`

Places the concept in the bootstrapping hierarchy.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `level` | INTEGER | Hierarchy level (1-4) |
| `description` | TEXT | What this level means |
| `components` | TEXT | What it's built from |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Levels:**
- Level 1: Primitive - directly grounded in core cognition or experience
- Level 2: Simple composite - combines Level 1 concepts
- Level 3: Complex composite - combines Level 2 concepts
- Level 4: Theoretical - highly abstract, far from experience

**Source:**
- Initial: `llm_analysis` (LLM assesses complexity)
- Computed: `internal_compute` (from component analysis)

---

### Table: `concept_built_from`

Lists the component concepts from which this was bootstrapped.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `component_concept` | VARCHAR(200) | Component name |
| `component_level` | INTEGER | That component's level |
| `contribution` | TEXT | What it contributes |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Source:**
- Initial: `llm_analysis` (LLM identifies components)
- Evidence: `evidence_testing` (evidence reveals components)

**Example:**
```
component_concept: "Sovereignty"
component_level: 2
contribution: "Provides authority/control dimension from political philosophy"
```

---

### Table: `concept_core_cognition`

Identifies engagement with innate cognitive systems.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `core_system` | VARCHAR(50) | Which core system |
| `engagement` | VARCHAR(20) | strong/moderate/weak/none |
| `how_activated` | TEXT | How the concept engages this system |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Core Systems (Carey's inventory):**
- `object`: Bounded physical objects
- `number`: Approximate magnitude
- `agency`: Intentional agents
- `in-group/out-group`: Social categories
- `contamination`: Purity/pollution

**Source:**
- Initial: `llm_analysis` (LLM identifies core cognition engagement)
- Evidence: `evidence_testing` (evidence shows cognitive patterns)

**Example:**
```
core_system: "in-group/out-group"
engagement: strong
how_activated: "Us vs. them framing; domestic vs. foreign tech"
```

---

### Table: `concept_placeholder_structures`

Identifies partial structures awaiting elaboration.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `placeholder` | VARCHAR(100) | What's placeholder |
| `content_type` | VARCHAR(30) | procedural/evaluative/categorical/ontological |
| `current_fill_status` | VARCHAR(30) | largely_empty/partially_filled/contested/assumed_not_elaborated |
| `elaboration_needed` | TEXT | What elaboration is needed |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Content Types:**
- `procedural`: How to do something
- `evaluative`: How to assess success/failure
- `categorical`: What belongs in category
- `ontological`: What kind of thing it is

**Source:**
- Initial: `llm_analysis` (LLM identifies gaps)
- Evidence: `evidence_testing` (evidence shows unfilled placeholders)

**Example:**
```
placeholder: "How to achieve it"
content_type: procedural
current_fill_status: largely_empty
elaboration_needed: "Massive - no clear path to actual sovereignty"
```
*Interpretation: Everyone uses the term but no one has actually worked out how to achieve it.*

---

### Table: `concept_bootstrapping_constraints`

Identifies cognitive constraints on learning/using the concept.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `constraint_type` | VARCHAR(50) | working_memory/analogical_mapping/causal_learning/coherence |
| `description` | TEXT | What the constraint is |
| `severity` | VARCHAR(20) | very_high/high/moderate/low |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Constraint Types:**
- `working_memory`: Too many things to hold in mind
- `analogical_mapping`: Source concepts don't map well
- `causal_learning`: Cause-effect too complex/delayed
- `coherence`: Components don't fit together

**Source:**
- Initial: `llm_analysis` (LLM identifies cognitive demands)
- Evidence: `evidence_testing` (evidence shows learning difficulties)

---

### Table: `concept_incommensurability`

Maps incommensurability with other conceptual frameworks.

| Field | Type | Description |
|-------|------|-------------|
| `id` | SERIAL | Primary key |
| `concept_id` | INTEGER FK | The concept |
| `with_concept` | VARCHAR(200) | The other concept/framework |
| `incommensurability_type` | VARCHAR(30) | partial/structural/strong/complete |
| `description` | TEXT | What can't translate |
| `source_type` | VARCHAR(30) | |
| `source_reference` | TEXT | |
| `confidence` | FLOAT | |

**Incommensurability Types:**
- `partial`: Some translation possible
- `structural`: Deep structural incompatibility
- `strong`: Very limited translation
- `complete`: No translation possible

**Source:**
- Initial: `llm_analysis` (LLM identifies translation failures)
- Evidence: `evidence_testing` (evidence shows communication failures)

---

## 13. Cross-Dimensional Analysis

### How Dimensions Interrelate

The nine dimensions are not independent - they illuminate each other:

| Connection | What It Reveals |
|------------|-----------------|
| Quinean inferences → Brandomian commitments | What the web structure commits users to |
| Sellarsian hidden commitments → Bachelardian obstacles | Hidden assumptions that block understanding |
| Deleuzian components → Carey bootstrap structure | What the concept is built from |
| Canguilhem vitality → Hacking looping effects | Whether loops are strengthening or weakening the concept |
| Blumenberg metaphors → Sellarsian givenness | How metaphors create false foundations |
| Brandomian challenges → Canguilhem health | Unanswered challenges indicate declining health |

### Cross-Dimensional Consistency Checks

The system can compute consistency across dimensions:

1. **Quinean-Brandomian**: Do inferences match commitments?
2. **Sellarsian-Bachelardian**: Do hidden commitments align with obstacles?
3. **Deleuzian-Carey**: Does component analysis match bootstrap analysis?
4. **Canguilhem-Hacking**: Does evolution history match looping effects?
5. **Blumenberg-Sellarsian**: Do metaphors explain what's treated as given?

### Feedback Triggers

When testing finds inconsistencies, it generates feedback:

```
If Quinean_inference[X] conflicts with Brandomian_commitment[Y]:
    Generate feedback:
        dimension: brandomian
        feedback_type: commitment_violated
        affected_table: concept_commitments
        cross_reference: concept_inferences[X]
```

---

## 14. Feedback System

### Feedback Types by Dimension

Each dimension has specific feedback types (81 total). When evidence tests a concept, it generates feedback categorized by:

1. **Dimension**: Which philosophical framework detected the issue
2. **Feedback Type**: Specific issue within that framework
3. **Severity**: critical/major/moderate/minor
4. **Affected Table**: Which table needs revision
5. **Suggested Action**: What to do about it

### Feedback → Revision Workflow

```
1. Evidence cluster tests concept
2. LLM analyzes using dimension-specific lens
3. Feedback generated with dimension/type/severity
4. Feedback reviewed by editors
5. If accepted:
   - Specific table row is revised
   - Source changes to evidence_testing
   - Confidence updated
   - Revision logged
```

### Sample Feedback Record

```json
{
  "evidence_test_id": 456,
  "dimension": "brandomian",
  "feedback_type": "challenge_unanswered",
  "severity": "critical",
  "summary": "Gulf $2T investment hasn't produced Series B capability",
  "details": "The commitment that 'investment leads to capability' is directly challenged by the Gulf states' experience...",
  "affected_table": "concept_challenges",
  "affected_row_id": null,
  "evidence_basis": "Cluster 67 evidence from Gulf tech investment analysis",
  "philosophical_significance": "If investment doesn't lead to capability, a core commitment of the concept is violated",
  "suggested_action": "Add new challenge record; change commitment confidence from 0.85 to 0.70",
  "confidence": 0.92,
  "status": "pending"
}
```

---

## 15. Workflow Summary

### Phase 1: Concept Creation

**User Input:**
1. User provides concept name and initial definition
2. Q&A wizard elicits domain, first appearance, usage context
3. User may upload documents for LLM to analyze

**LLM Analysis:**
4. LLM elaborates definition across all 9 dimensions
5. Initial values generated with source_type: `llm_analysis`
6. Confidence scores assigned based on task complexity

**Result:** Concept record created with ~50-80 initial values across all tables

### Phase 2: Internal Computation

**Derived Values:**
1. Entrenchment score computed from inference counts + centrality
2. Health status derived from vitality indicators
3. Web position computed from inference network
4. Cross-dimensional consistency checked

**Result:** Computed values added with source_type: `internal_compute`

### Phase 3: Evidence Testing

**Evidence Input:**
1. Essay-flow evidence clusters test concept
2. Each cluster tests specific tables/values
3. LLM analyzes using dimension-specific lens

**Feedback Generation:**
4. Dimension-specific feedback generated
5. Severity and suggested actions assigned
6. Feedback queued for editorial review

**Result:** Feedback records created with evidence basis

### Phase 4: Editorial Review

**Review Process:**
1. Editors review pending feedback
2. Accept, reject, or modify suggestions
3. Accepted feedback triggers revisions

**Revision:**
4. Specific table rows updated
5. Source_type changes to `evidence_testing`
6. Source_reference points to evidence cluster
7. Confidence updated based on evidence strength

**Result:** Concept values refined by evidence

### Phase 5: Ongoing Evolution

**Continuous:**
1. New evidence clusters continue testing
2. Health status recomputed
3. Evolution stage may advance
4. Vital norms checked for violations

**Periodic:**
5. Full re-analysis may be triggered
6. Cross-dimensional consistency rechecked
7. Documentation updated

---

## Appendix A: Source Type Decision Tree

```
Is this value from the user directly?
├─ Yes → source_type: user_input
└─ No → Was it computed from other DB values?
         ├─ Yes → source_type: internal_compute
         └─ No → Was it derived from evidence testing?
                  ├─ Yes → source_type: evidence_testing
                  └─ No → Was it imported from external source?
                           ├─ Yes → source_type: import
                           └─ No → source_type: llm_analysis
```

## Appendix B: Confidence Assignment Guidelines

| Scenario | Confidence Range |
|----------|------------------|
| User states with certainty | 0.95-1.0 |
| User states with hedging | 0.70-0.90 |
| LLM derives from clear definition | 0.80-0.90 |
| LLM infers from context | 0.65-0.80 |
| LLM speculates | 0.50-0.65 |
| Evidence strongly supports | 0.85-0.95 |
| Evidence partially supports | 0.65-0.85 |
| Evidence is mixed | 0.50-0.65 |
| Computed from high-confidence inputs | inherit average |
| Computed from mixed inputs | inherit minimum |

## Appendix C: Quick Reference - All 47 Tables

| # | Table | Dimension | Purpose |
|---|-------|-----------|---------|
| 1 | concepts | Core | Master concept record |
| 2 | concept_inferences | Quinean | Inferential connections |
| 3 | concept_web_tensions | Quinean | Tensions with other concepts |
| 4 | concept_web_position | Quinean | Position in belief web |
| 5 | concept_ontological_dependence | Quinean | What concept presupposes |
| 6 | concept_revision_ramifications | Quinean | Consequences of revision |
| 7 | concept_givenness | Sellarsian | What's treated as given |
| 8 | concept_hidden_commitments | Sellarsian | Baked-in assumptions |
| 9 | concept_space_of_reasons | Sellarsian | Justificatory role |
| 10 | concept_functional_role | Sellarsian | Role in discourse |
| 11 | concept_image_tension | Sellarsian | Manifest vs scientific |
| 12 | concept_commitments | Brandomian | Deontic commitments |
| 13 | concept_inferential_roles | Brandomian | Material inferences |
| 14 | concept_perspectival_content | Brandomian | De dicto vs de re |
| 15 | concept_challenges | Brandomian | Challenges to commitments |
| 16 | concept_components | Deleuzian | Concept's components |
| 17 | concept_zones_of_indiscernibility | Deleuzian | Component overlaps |
| 18 | concept_consistency | Deleuzian | Internal/external coherence |
| 19 | concept_plane_of_immanence | Deleuzian | Operating plane |
| 20 | concept_personae | Deleuzian | Who deploys concept |
| 21 | concept_obstacles | Bachelardian | Epistemological obstacles |
| 22 | concept_cognitive_stage | Bachelardian | Stage of thinking |
| 23 | concept_psychoanalytic_function | Bachelardian | Unconscious needs served |
| 24 | concept_regional_rationality | Bachelardian | Domain of rationality |
| 25 | concept_evolution | Canguilhem | Historical development |
| 26 | concept_filiation | Canguilhem | Conceptual lineage |
| 27 | concept_vital_norms | Canguilhem | Concept's own norms |
| 28 | concept_milieu | Canguilhem | Operating environment |
| 29 | concept_vitality_indicators | Canguilhem | Health metrics |
| 30 | concept_reasoning_styles | Hacking | Associated reasoning styles |
| 31 | concept_looping_effects | Hacking | How concept changes reality |
| 32 | concept_kinds_created | Hacking | New kinds brought into being |
| 33 | concept_possibility_space | Hacking | What's made thinkable |
| 34 | concept_metaphors | Blumenberg | Root metaphors |
| 35 | concept_metakinetics | Blumenberg | Metaphor transformations |
| 36 | concept_nonconceptuality | Blumenberg | What resists conceptualization |
| 37 | concept_lifeworld_connection | Blumenberg | Tension with lived experience |
| 38 | concept_hierarchy | Carey | Bootstrapping level |
| 39 | concept_built_from | Carey | Component concepts |
| 40 | concept_core_cognition | Carey | Core cognitive systems |
| 41 | concept_placeholder_structures | Carey | Unfilled slots |
| 42 | concept_bootstrapping_constraints | Carey | Cognitive constraints |
| 43 | concept_incommensurability | Carey | Translation failures |

---

*Document Version: 1.0*
*Schema Version: v5*
*Last Updated: 2025-12-16*
*Total Tables: 47 (including master concepts table and dimension_feedback)*
*Total Feedback Types: 81*
