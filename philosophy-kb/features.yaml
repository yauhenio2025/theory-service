meta:
  exported_at: '2025-12-16 19:45:46'
  total_features: 193
features:
- id: non-predetermined-stage-sequencing
  name: Non-Predetermined Stage Sequencing
  summary: Generate later elicitation stages only after processing earlier responses, preventing the predetermined feel 
    of pre-scripted interrogation.
  description: "Generate later elicitation stages only after processing earlier responses, preventing the predetermined feel
    of pre-scripted interrogation.\n\nRather than presenting a fixed question sequence, the system generates stage 2 questions
    only after stage 1 is answered, allowing the inquiry trajectory to genuinely respond to user input. This maintains the
    feeling that the process is exploring rather than administering a survey, supporting authentic knowledge extraction.\n\
    \n**When to use:** When extracting complex or partially-formed user knowledge; when premature question exposure would
    anchor or constrain responses; when the value lies in probing rather than surveying."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_dynamic_elicitation_injection
    how_embodied: extends
    confidence: 0.8
  - principle_id: prn_provisional_articulation_as_catalyst
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_staged_adaptive_interrogation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: cognitive-task-to-scaffolding-modality-matching
  name: Cognitive Task to Scaffolding Modality Matching
  summary: Deploy questions, visualizations, path-diagrams, and interfaces as distinct tools matched to specific 
    cognitive support needs.
  description: "Deploy questions, visualizations, path-diagrams, and interfaces as distinct tools matched to specific cognitive
    support needs.\n\nDifferent cognitive operations—imagining possibilities, tracing implications, articulating beliefs—require
    different external supports. The system treats questions as one modality among many, selecting or combining visualizations,
    interactive interfaces, and path diagrams based on what the cognitive task actually requires rather than defaulting to
    verbal interrogation.\n\n**When to use:** When verbal questions hit diminishing returns; when users need to 'see' rather
    than 'answer'; when the cognitive task is spatial (path exploration) rather than propositional (assertion)."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_multimodal_cognitive_scaffolding
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cognitive_task_matched_presentation
    how_embodied: specializes
    confidence: 0.8
  - principle_id: prn_externalized_imagination_infrastructure
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: choice-impact-topology-rendering
  name: Choice-Impact Topology Rendering
  summary: Visualize the network of downstream implications when a conceptual choice is made one way versus another.
  description: "Visualize the network of downstream implications when a conceptual choice is made one way versus another.\n\
    \nWhen users face definitional or conceptual decisions, the system renders visible the propagation topology—showing how
    defining concept X one way affects arguments Y and Z, versus defining it differently. This makes conceptual interdependencies
    navigable rather than requiring users to hold complex implication chains mentally.\n\n**When to use:** When conceptual
    definitions have cascading effects on argument structure; when users need to understand trade-offs between formulation
    choices; when the 'cost' of a decision is its downstream constraints."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_externalized_imagination_infrastructure
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_possibility_as_foreclosure_warning
    how_embodied: extends
    confidence: 0.8
  - principle_id: prn_option_impact_preview
    how_embodied: specializes
    confidence: 0.8
  - principle_id: prn_impact_topology_materialization
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: provisional-formulation-as-knowledge-probe
  name: Provisional Formulation as Knowledge Probe
  summary: Output tentative conclusions and articulations mid-process to catalyze user's ability to express tacit 
    knowledge.
  description: "Output tentative conclusions and articulations mid-process to catalyze user's ability to express tacit knowledge.\n\
    \nRather than only asking questions, the system generates provisional answers, formulations, or conclusions at intermediate
    stages. These imperfect articulations serve as stimuli that help users recognize and correct toward what they actually
    think—extracting knowledge they 'may know but may not have yet articulated.'\n\n**When to use:** When users possess relevant
    knowledge but struggle to articulate it directly; when questions alone fail to surface tacit understanding; when seeing
    a 'wrong' answer helps clarify the 'right' one."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_externalized_imagination_infrastructure
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_embodied_decision_substrate
    how_embodied: extends
    confidence: 0.8
  - principle_id: prn_provisional_articulation_as_catalyst
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: type-generic-element-processing
  name: Type-Generic Element Processing
  summary: Processing mechanisms operate on categories of structural elements rather than hardcoded specific element 
    types, enabling automatic coverage of future additions.
  description: "Processing mechanisms operate on categories of structural elements rather than hardcoded specific element
    types, enabling automatic coverage of future additions.\n\nRather than building separate refinement logic for 'concepts',
    'dialectics', and 'propositions' individually, the system treats these as instances of 'theoretical structural elements'
    and processes them polymorphically. When new element types are added to the theory package, they automatically receive
    appropriate refinement processing without code changes.\n\n**When to use:** When designing systems that must handle evolving
    schemas where new structural element types may be introduced over time."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_extensibility_as_design_criterion
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_type_polymorphic_processing
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: precision-forcing-refinement-questions
  name: Precision-Forcing Refinement Questions
  summary: Refinement stages include questions specifically designed to force users or LLMs toward greater precision on 
    vague theoretical elements.
  description: "Refinement stages include questions specifically designed to force users or LLMs toward greater precision
    on vague theoretical elements.\n\nQuestions in the refinement phase are crafted to target imprecision as a specific property,
    demanding more exact specification of concepts and dialectics. This treats vagueness not as an inevitable state but as
    something that targeted questioning can systematically address and reduce.\n\n**When to use:** When theoretical elements
    like concepts or dialectics have been generated but remain underdetermined and need sharpening before downstream use."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_staged_adaptive_interrogation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_precision_forcing_interrogation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: schema-introspective-question-generation
  name: Schema-Introspective Question Generation
  summary: Refinement questions are generated by introspecting what structural element types currently exist in the 
    theory package rather than using a fixed question set.
  description: "Refinement questions are generated by introspecting what structural element types currently exist in the theory
    package rather than using a fixed question set.\n\nThe refinement stage examines the current schema to discover what theoretical
    elements are present (propositions, concepts, dialectics, etc.) and generates appropriate refinement questions for each
    element type. This allows the questioning to adapt automatically when new structural elements are added to the theory
    package.\n\n**When to use:** When building refinement or interrogation stages that need to remain valid as the underlying
    data schema evolves with new element types."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_extensibility_as_design_criterion
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_schema_reflexive_generation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: explicit-criterion-threading-between-llm-calls
  name: Explicit Criterion Threading Between LLM Calls
  summary: Pass variables, criteria, and constraints as explicit structured data between collaborating LLM invocations.
  description: "Pass variables, criteria, and constraints as explicit structured data between collaborating LLM invocations.\n\
    \nWhen multiple LLMs work across a multi-stage process, make the handoff of governing criteria explicit rather than implicit.
    Each stage should receive and can query the current process plan, relevant constraints, and evaluation criteria as structured
    data. This enables both asking the right questions and knowing when/how to propose restructuring.\n\n**When to use:**
    Apply whenever orchestrating multiple LLM calls that need to maintain coherence with each other and with an evolving process
    plan, especially in agentic or pipeline architectures."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_process_parameterized_questioning
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_contrastive_context_enrichment
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_inter_stage_criterion_propagation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: result-triggered-process-restructuring
  name: Result-Triggered Process Restructuring
  summary: Enable LLMs to propose modifications to the workflow structure based on accumulated results.
  description: "Enable LLMs to propose modifications to the workflow structure based on accumulated results.\n\nAs processing
    proceeds and results accumulate, LLMs should be able to propose adjustments to the workflow itself—not just the content.
    This creates a feedback loop where content outcomes inform process evolution, making the system dynamically adaptive rather
    than following a fixed plan regardless of what emerges.\n\n**When to use:** Apply in extended multi-stage workflows where
    early results may reveal that the planned process is suboptimal, and where the cost of continuing a misaligned process
    exceeds the cost of restructuring."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_runtime_strategy_adaptation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: constrains
    confidence: 0.8
  - principle_id: prn_bidirectional_process_content_evolution
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: collaborative-process-design-with-versioning
  name: Collaborative Process Design with Versioning
  summary: Introduce an early stage where LLMs propose a workflow, users adjust it, and version changes are tracked.
  description: "Introduce an early stage where LLMs propose a workflow, users adjust it, and version changes are tracked.\n\
    \nAdd an explicit process-design phase where, after initial questions, an LLM generates a proposed workflow/flow structure.
    Users can modify this proposal, and all versions of the process design are tracked. This makes the workflow itself a first-class
    artifact that both parties shape rather than a hidden system constraint.\n\n**When to use:** Apply when building multi-stage
    systems where users should have agency over process structure, particularly when different users may need different workflow
    configurations."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_refinement_versioning
    how_embodied: applies
    confidence: 0.8
  - principle_id: prn_early_consequential_decisions
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_explicit_process_externalization
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: stage-contingent-question-calibration
  name: Stage-Contingent Question Calibration
  summary: Adjust question types based on which processing stages exist or have been removed from the workflow.
  description: "Adjust question types based on which processing stages exist or have been removed from the workflow.\n\nWhen
    formulating questions at any stage, explicitly check the current process plan to determine question granularity. If downstream
    stages exist for gathering specific evidence, ask for typologies and patterns; if those stages have been removed, ask
    for specific examples directly. This prevents asking the wrong type of question for the available process structure.\n\
    \n**When to use:** Apply when designing question-generation prompts for any stage that feeds into optional or configurable
    downstream stages, especially refinement or elicitation phases."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_stage_appropriate_question_types
    how_embodied: specializes
    confidence: 0.8
  - principle_id: prn_process_parameterized_questioning
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_downstream_aware_generation
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: prn_meta_content_suppression
  name: LLM Meta-Commentary Filter
  summary: Filter LLM meta-commentary from end-user outputs, removing self-referential commentary about the generation 
    process that represents internal processing artifacts.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_meta_content_suppression
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: prn_multimodal_output_verification
  name: LLM Multimodal Verification
  summary: Cross-modal LLM verification of generated outputs, sending outputs to models that can perceive that modality 
    and confirm alignment with specifications.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_input_anchored_validation
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: prn_input_anchored_validation
  name: LLM Input Fidelity Check
  summary: LLM output validation by comparison to input ground truth, explicitly checking that outputs remain faithful 
    to inputs rather than evaluating outputs in isolation.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_correction_before_commitment
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: prn_economic_model_tiering
  name: LLM Model Tiering
  summary: Cost-optimized LLM model selection by pipeline stage, using cheaper/faster models for constrained tasks while
    reserving expensive models for unconstrained generation.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_resource_proportionality
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: prn_human_authority_gate
  name: LLM Verification Gate
  summary: Verification gates between LLM generation and system commitment, interposing verification and correction 
    stages that complete before any changes are committed.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_execution_readiness_criteria
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: prn_anticipatory_model_instantiation
  name: LLM Anticipatory Model Construction
  summary: LLMs construct provisional output models from first inputs to guide data collection, building anticipatory 
    models from earliest data points to identify information gaps.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_schema_as_hypothesis
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: preemptive-output-structure-anticipation
  name: Preemptive Output Structure Anticipation
  summary: Work backward from anticipated final output structures to identify what information must be elicited, 
    treating output requirements as constraints on input gathering.
  description: "Work backward from anticipated final output structures to identify what information must be elicited, treating
    output requirements as constraints on input gathering.\n\nThe system explicitly reasons about what throughlines might
    exist and what weight distributions they would require, using this anticipation to identify gaps in current knowledge.
    This transforms the elicitation process from forward-flowing data gathering into bidirectional reasoning where anticipated
    outputs constrain and guide the questions asked.\n\n**When to use:** Use when final outputs have structural requirements
    (like weighted throughlines) that depend on information not naturally surfaced by standard elicitation, requiring deliberate
    backward reasoning from output needs to input requirements."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_downstream_aware_generation
    how_embodied: implements
    confidence: 0.8
  - principle_id: prn_anticipatory_model_instantiation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: continuous-background-weight-refinement
  name: Continuous Background Weight Refinement
  summary: Maintain and progressively refine weight hypotheses throughout all user interactions rather than computing 
    weights only at a designated stage.
  description: "Maintain and progressively refine weight hypotheses throughout all user interactions rather than computing
    weights only at a designated stage.\n\nInstead of treating weight determination as a discrete phase that occurs after
    data collection, the system runs weight inference as a continuous background process. Each new user answer updates the
    provisional weight distribution, with the model becoming progressively more accurate and revealing which aspects remain
    underdetermined.\n\n**When to use:** Apply in workflows where multiple independent dimensions must be weighted relative
    to each other and where user responses provide indirect evidence about relative importance across the entire interaction."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_continuous_background_synthesis
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_continuous_strategic_reasoning
    how_embodied: Created by refactoring engine
    confidence: 0.8
  - principle_id: prn_iterative_theory_data_dialectic
    how_embodied: extends
    confidence: 0.8
  grounding_count: 0
- id: weight-gap-targeted-question-insertion
  name: Weight-Gap Targeted Question Insertion
  summary: Strategically inject questions into the elicitation flow specifically designed to resolve weight distribution
    ambiguities revealed by anticipatory models.
  description: "Strategically inject questions into the elicitation flow specifically designed to resolve weight distribution
    ambiguities revealed by anticipatory models.\n\nWhen the provisional throughline model reveals that weight distribution
    cannot be determined from existing data, the system inserts targeted questions at opportune moments rather than following
    a fixed question sequence. These questions are designed specifically to disambiguate weight assignments before formal
    weight generation occurs.\n\n**When to use:** Use when anticipated outputs require parametric decisions (like weights,
    priorities, or distributions) that cannot be reliably inferred from standard elicitation questions alone."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_proactive_insufficiency_signaling
    how_embodied: implements
    confidence: 0.8
  - principle_id: prn_dynamic_elicitation_injection
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: first-input-throughline-projection
  name: First-Input Throughline Projection
  summary: Instruct LLMs to begin constructing provisional models of final outputs immediately upon receiving the first 
    user input.
  description: "Instruct LLMs to begin constructing provisional models of final outputs immediately upon receiving the first
    user input.\n\nRather than waiting until all user data is collected, the system prompts the LLM to start anticipating
    what throughlines might emerge from the very first answer. This creates an evolving hypothesis about final structures
    that gets refined with each subsequent input, transforming passive data collection into active model-building.\n\n**When
    to use:** Apply when designing multi-step elicitation flows where the final output structure depends on synthesizing information
    across all steps, and where early anticipation can reveal what additional information is needed."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_forward_staged_data_harvesting
    how_embodied: extends
    confidence: 0.8
  - principle_id: prn_anticipatory_model_instantiation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: correction-then-commit-gating
  name: Correction-Then-Commit Gating
  summary: Parse verification suggestions into corrections, apply them to outputs, and only then execute consequential 
    operations.
  description: "Parse verification suggestions into corrections, apply them to outputs, and only then execute consequential
    operations.\n\nThe verification layer produces correction suggestions rather than direct fixes. These suggestions are
    parsed, applied to modify the original outputs, and the corrected version is what gets committed to downstream processes.
    This creates a gate where no refactoring or permanent changes occur until validation passes.\n\n**When to use:** When
    outputs drive automated refactoring, code changes, or other irreversible operations where pre-commitment correction is
    cheaper than post-commitment rollback."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_human_authority_gate
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_correction_before_commitment
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cybernetic_feedback
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: input-grounded-field-comparison
  name: Input-Grounded Field Comparison
  summary: Structure verification prompts to explicitly compare output fields against original input fields as ground 
    truth.
  description: "Structure verification prompts to explicitly compare output fields against original input fields as ground
    truth.\n\nFrame the verification task as checking whether each output field correctly derives from or matches corresponding
    input data. The verifier receives both inputs and outputs, with instructions to identify any fields that don't properly
    reflect the source inputs. This anchors validation in concrete comparison rather than abstract quality assessment.\n\n\
    **When to use:** When outputs contain structured fields that should faithfully represent input data, and hallucination
    risk manifests as field-level fabrication or distortion."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_input_anchored_validation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_provenance_preservation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_verification_easier_than_generation
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: cross-model-economic-verification
  name: Cross-Model Economic Verification
  summary: Assign verification tasks to cheaper/faster models than the primary generation model.
  description: "Assign verification tasks to cheaper/faster models than the primary generation model.\n\nUse an economical
    model (e.g., Haiku 4.5) to verify outputs from a more capable but expensive model (e.g., Sonnet). Verification is a constrained
    comparison task that doesn't require the full reasoning capacity of premium models, making this economically efficient
    without sacrificing quality.\n\n**When to use:** When pipeline includes multiple LLM stages and cost optimization matters,
    particularly for verification stages that can tolerate reduced capability."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_resource_proportionality
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cognitive_division_of_labor
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_economic_model_tiering
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: secondary-llm-verification-layer
  name: Secondary LLM Verification Layer
  summary: Interpose a dedicated LLM pass specifically for validating outputs before they trigger downstream actions.
  description: "Interpose a dedicated LLM pass specifically for validating outputs before they trigger downstream actions.\n\
    \nAfter primary generation, route outputs through a second LLM instance tasked solely with verification rather than generation.
    This verification layer compares outputs against inputs to identify mismatches, hallucinations, or drift. The separated
    concerns allow verification-optimized prompting distinct from generation-optimized prompting.\n\n**When to use:** When
    LLM outputs will trigger consequential changes (refactoring, database updates, API calls) where hallucinations would cause
    harm that's expensive to reverse."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_verification_easier_than_generation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_phase_separated_processing
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_correction_before_commitment
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: feat_structured_decision_presentation
  name: Structured Decision Presentation
  summary: When LLM outputs require human evaluation or selection, format for scanability and comparison through 
    structured visual hierarchy (bullets, line breaks, grouping) over compact prose.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cognitive_task_matched_presentation
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_optimistic_automation_with_undo
  name: Optimistic Automation with Undo
  summary: For high-confidence, low-stakes automated actions, proceed with the action while proactively notifying users 
    and providing easy override mechanisms.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_optimistic_execution
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_llm_capability_impact_analysis
  name: LLM Capability Impact Analysis
  summary: When users propose new system capabilities, LLMs should analyze how additions cascade through processing 
    stages and automatically identify required adjustments.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_change_impact_propagation
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_context_driven_system_specialization
  name: Context-Driven System Specialization
  summary: Design systems where contextual content (documents, user responses, examples) functions as runtime 
    configuration that transforms generic systems into domain-specific tools.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_data_as_program
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_llm_continuous_strategy_adaptation
  name: LLM Continuous Strategy Adaptation
  summary: LLM systems should engage in ongoing strategic reasoning that re-evaluates approach and course-corrects based
    on accumulated context, rather than executing pre-planned pipelines.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_runtime_strategy_adaptation
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_llm_optimized_data_structures
  name: LLM-Optimized Data Structures
  summary: Design data structures anticipating that LLMs will be the primary consumers, optimizing for machine parsing 
    and reasoning rather than human readability.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_consumer_optimized_representation
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: dynamic-strategic-course-correction
  name: Dynamic Strategic Course-Correction
  summary: LLMs should continuously re-strategize based on accumulated user answers and contextual pointers.
  description: "LLMs should continuously re-strategize based on accumulated user answers and contextual pointers.\n\nRather
    than executing predetermined pipelines, the system should 'strategize on the fly and course-correct based on user answers,
    pointers to more contextual docs.' Each new input triggers re-evaluation of approach, making strategy an ongoing activity
    interleaved with execution.\n\n**When to use:** When user engagement reveals information that should reshape the overall
    approach, not just immediate outputs"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cybernetic_feedback
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_runtime_pipeline_orchestration
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_continuous_strategic_reasoning
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: maximum-resource-allocation-for-strategic-reasonin
  name: Maximum Resource Allocation for Strategic Reasoning
  summary: Explicitly allocate highest available computational resources when tasks require strategic adaptation.
  description: "Explicitly allocate highest available computational resources when tasks require strategic adaptation.\n\n\
    When strategic reasoning, course-correction, and on-the-fly adaptation are required, configure LLMs with maximum token
    limits and reasoning modes rather than economizing. The instruction 'shouldn't spare any resources' treats reasoning quality
    as the paramount concern over efficiency.\n\n**When to use:** When tasks require dynamic strategy formulation rather than
    routine processing, especially when user context is evolving"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_reasoning_resource_maximization
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_resource_proportionality
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: dual-channel-progressive-specialization
  name: Dual-Channel Progressive Specialization
  summary: Configure systems through both pre-loaded contextual documents and emergent user dialogue responses.
  description: "Configure systems through both pre-loaded contextual documents and emergent user dialogue responses.\n\nCustomization
    depth increases through two complementary channels: a contextual docs folder provides initial domain grounding, while
    user responses during conversation add deeper, more specific configuration. The combination produces specialization neither
    channel could achieve alone.\n\n**When to use:** When building adaptive systems that need both baseline domain knowledge
    and real-time personalization"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_context_as_configuration
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_staged_adaptive_interrogation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_dialogue_emergent_relevance
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: domain-agnostic-initial-architecture
  name: Domain-Agnostic Initial Architecture
  summary: Design systems to start without domain commitment, becoming specialized only through runtime inputs.
  description: "Design systems to start without domain commitment, becoming specialized only through runtime inputs.\n\nThe
    framework begins as a generic structure not configured for any specific use case (foundation, VC, essay writing). Domain
    specificity emerges entirely from contextual documents and user interactions rather than initial design choices. This
    enables the same core architecture to serve radically different purposes.\n\n**When to use:** When building systems that
    must serve multiple domains or when the specific domain won't be known until runtime"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_domain_transcendent_abstraction
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_context_as_configuration
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: just-in-time-profile-construction
  name: Just-In-Time Profile Construction
  summary: Build structured entity profiles (e.g., philanthropy profiles) only after sufficient conversational context 
    exists to determine useful structure.
  description: "Build structured entity profiles (e.g., philanthropy profiles) only after sufficient conversational context
    exists to determine useful structure.\n\nDefer the construction of structured profiles from document collections until
    dialogue has established what aspects matter for downstream tool functions. This ensures profiles are built in a way that
    serves actual use rather than speculative completeness, with structure emerging from demonstrated need rather than anticipated
    need.\n\n**When to use:** When creating entity profiles that must serve varied downstream functions, and optimal profile
    structure depends on how the profile will be used."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_staging_processing_separation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_function_based_on_demand_retri
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_dialogue_emergent_relevance
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: conversation-guided-extraction-targeting
  name: Conversation-Guided Extraction Targeting
  summary: Use the dynamics of user-LLM dialogue to discover what aspects of staged documents are actually relevant to 
    extract.
  description: "Use the dynamics of user-LLM dialogue to discover what aspects of staged documents are actually relevant to
    extract.\n\nRather than pre-determining extraction schemas, allow the evolving conversation between user and LLM to generate
    extraction criteria. The dialogue itself becomes a discovery mechanism that reveals what the user actually needs from
    the document collection, making extraction more targeted and valuable.\n\n**When to use:** When document collections are
    large and varied, and relevance cannot be determined without understanding user intent through interaction."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_dialectical_refinement
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_contextual_extraction_superiority
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_dialogue_emergent_relevance
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: document-collection-staging-without-processing
  name: Document Collection Staging Without Processing
  summary: Register document folders with the system for availability without triggering immediate extraction or 
    structuring.
  description: "Register document folders with the system for availability without triggering immediate extraction or structuring.\n\
    \nPoint the tool to folders containing relevant documents (e.g., philanthropy materials) to make them accessible for later
    use, but do not perform upfront extraction or transformation. This separates resource availability from resource processing,
    allowing documents to be staged early while extraction criteria are determined later through use.\n\n**When to use:**
    When building tools that need access to external document collections but where relevance criteria are not yet clear at
    setup time."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_contextual_extraction_superiority
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_staging_processing_separation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: domain-portable-process-architecture
  name: Domain-Portable Process Architecture
  summary: Abstracting process structures so the same operational modules serve journalism, academia, policy work, and 
    other domains through parameterization rather than separate implementations.
  description: "Abstracting process structures so the same operational modules serve journalism, academia, policy work, and
    other domains through parameterization rather than separate implementations.\n\nThe core processing modules (generating
    through-lines, strategic items, semantic clustering) are designed domain-agnostically, with domain-specific behavior emerging
    from the input materials and configured parameters rather than hard-coded domain logic. This requires identifying the
    truly universal operations across domains and making domain-specific aspects configurable rather than structural.\n\n\
    **When to use:** When building tools intended to serve multiple institutional contexts (newsrooms, foundations, academic
    institutions) and when the underlying cognitive operations are similar despite surface differences in outputs."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_context_as_configuration
    how_embodied: Created by refactoring engine
    confidence: 0.8
  - principle_id: prn_generative_personalization
    how_embodied: relates_to
    confidence: 0.8
  - principle_id: prn_context_specific_adaptation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_domain_transcendent_abstraction
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: arbitrary-point-content-injection
  name: Arbitrary-Point Content Injection
  summary: Enabling contextual inputs like articles, reports, or additional data to be inserted at any point in the 
    workflow rather than only at designated input stages.
  description: "Enabling contextual inputs like articles, reports, or additional data to be inserted at any point in the workflow
    rather than only at designated input stages.\n\nThe system supports inserting enrichment materials (news articles, policy
    reports, academic papers, grantee reports) before, during, or after core processing stages. This allows context to enhance
    processing at the moment it becomes most relevant—whether for initial framing, mid-process semantic clustering, or late-stage
    validation. Input architecture is designed for permeability rather than gatekeeping.\n\n**When to use:** When the relevance
    of supplementary materials depends on what has been generated so far, and when users may discover useful context mid-process
    that should inform subsequent operations."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_forward_staged_data_harvesting
    how_embodied: relates_to
    confidence: 0.8
  - principle_id: prn_arbitrary_insertion_architecture
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: task-driven-pipeline-composition
  name: Task-Driven Pipeline Composition
  summary: Assembling the sequence and quantity of processing stages dynamically based on task requirements and emerging
    results rather than fixed templates.
  description: "Assembling the sequence and quantity of processing stages dynamically based on task requirements and emerging
    results rather than fixed templates.\n\nRather than prescribing a fixed flow, the system determines which operations to
    run and in what order based on the specific task, user inputs, and intermediate results. This includes responding to user
    interaction during processing and adjusting the remaining pipeline accordingly. The distinction shifts from predetermined
    outcome to predetermined operational repertoire.\n\n**When to use:** When different tasks require fundamentally different
    processing patterns even within the same domain, and when user feedback during processing should influence subsequent
    steps."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_event_driven_refinement
    how_embodied: relates_to
    confidence: 0.8
  - principle_id: prn_cybernetic_feedback
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_runtime_pipeline_orchestration
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: position-agnostic-module-definition
  name: Position-Agnostic Module Definition
  summary: Designing operational modules that function identically regardless of where they appear in a processing 
    sequence.
  description: "Designing operational modules that function identically regardless of where they appear in a processing sequence.\n\
    \nModules are built to be self-contained units that can be invoked early (before generating through-lines), late (after
    strategy elucidation), or multiple times throughout a workflow. Each module operates on current state without assumptions
    about prior steps, enabling arbitrary sequencing. This requires explicit input/output contracts rather than implicit positional
    dependencies.\n\n**When to use:** When building flexible workflows where the optimal order of operations varies by task,
    user preference, or emerging results, and where the same operation may need to run multiple times at different stages."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_composable_process_primitives
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_staged_processing
    how_embodied: extends
    confidence: 0.8
  grounding_count: 0
- id: friction-prioritized-attention-allocation
  name: Friction-Prioritized Attention Allocation
  summary: Direct the core user action toward items causing structural conflict, treating harmonious integrations as 
    resolved background operations.
  description: "Direct the core user action toward items causing structural conflict, treating harmonious integrations as
    resolved background operations.\n\nExplicitly design the interaction flow so that friction-causing evidence commands primary
    attention and cognitive effort. Seamlessly integrated items are acknowledged but don't compete for attention. This inverts
    the common pattern of reviewing everything equally by making conflict the attention attractor.\n\n**When to use:** When
    processing mixed content streams where some items require human judgment and others don't; when trying to optimize human
    cognitive allocation across heterogeneous processing needs."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_friction_focused_attention_allocation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_resource_proportionality
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_cognitive_division_of_labor
    how_embodied: implements
    confidence: 0.8
  grounding_count: 0
- id: granular-post-hoc-override-controls
  name: Granular Post-Hoc Override Controls
  summary: Present auto-integrated items with check/uncheck toggles enabling selective acceptance or rejection after 
    automatic action.
  description: "Present auto-integrated items with check/uncheck toggles enabling selective acceptance or rejection after
    automatic action.\n\nRather than blocking on pre-approval or acting without recourse, provide interface controls that
    let users review and selectively override automatic decisions. Each integrated item becomes checkable/uncheckable, converting
    binary approve-all or reject-all into granular item-level control exercised after integration.\n\n**When to use:** When
    automatic actions need human oversight but shouldn't require exhaustive pre-approval; when users need efficient ways to
    correct edge cases without reviewing every item."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_act_notify_override_pattern
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_visual_state_legibility
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: implements
    confidence: 0.8
  grounding_count: 0
- id: silent-integration-with-disclosure
  name: Silent Integration with Disclosure
  summary: Automatically integrate naturally-fitting evidence while proactively informing users what was done and 
    offering preview.
  description: "Automatically integrate naturally-fitting evidence while proactively informing users what was done and offering
    preview.\n\nFor evidence that passes structural fit assessment without conflict, proceed with integration without blocking
    for approval. Simultaneously notify users of what was integrated and provide preview capability so they understand system
    actions. This treats non-conflicting integration as the default while maintaining transparency.\n\n**When to use:** When
    handling high-confidence, low-risk content additions where requiring pre-approval would create unnecessary friction without
    adding value."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_dual_mode_operation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_cognitive_division_of_labor
    how_embodied: implements
    confidence: 0.8
  - principle_id: prn_act_notify_override_pattern
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: fit-based-evidence-bifurcation
  name: Fit-Based Evidence Bifurcation
  summary: Route evidence to different processing pathways based on whether it harmonizes with or conflicts against 
    existing structural slots.
  description: "Route evidence to different processing pathways based on whether it harmonizes with or conflicts against existing
    structural slots.\n\nBefore attempting integration, assess each piece of evidence against target slots in the functional
    skeleton to determine structural compatibility. Evidence that naturally fits proceeds to automatic integration, while
    evidence causing friction routes to human-attention workflows. This assessment becomes the primary routing decision point.\n\
    \n**When to use:** When integrating heterogeneous content into structured frameworks where some items will fit naturally
    and others will require reconciliation or modification."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_content_based_routing
    how_embodied: implements
    confidence: 0.8
  - principle_id: prn_structural_fit_assessment_phase
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_conflict_triage
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: sub-option-dependent-revision-branching
  name: Sub-Option Dependent Revision Branching
  summary: Map revision requirements that vary based on which sub-options users select within each major interpretive 
    choice.
  description: "Map revision requirements that vary based on which sub-options users select within each major interpretive
    choice.\n\nBeyond showing impacts of top-level choices, pre-generate how different sub-options for integrating each reading
    create different revision patterns. This reveals the decision space as a branching tree where sub-choices within each
    interpretation have their own distinct cascading effects.\n\n**When to use:** When interpretive choices have nested sub-options
    and users need to understand how combinations of choices interact to determine final revision requirements"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_interpretive_cascade_instantiation
    how_embodied: extends
    confidence: 0.8
  - principle_id: prn_possibility_space_architecture
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: decision-support-container-matching
  name: Decision Support Container Matching
  summary: Select interface affordances (modals, sidebars, collapsibles) that match the cognitive requirements of the 
    decision task.
  description: "Select interface affordances (modals, sidebars, collapsibles) that match the cognitive requirements of the
    decision task.\n\nPre-generated decision support content should be presented through interface patterns chosen specifically
    for the cognitive task at hand. Comparison tasks need parallel visibility; exploration needs expandability. The container
    choice shapes how effectively users can process the pre-computed options.\n\n**When to use:** When implementing UI for
    presenting multiple pre-generated interpretive paths or integration options requiring user selection"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_decision_interface_modality_matching
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_format_for_decision_support
    how_embodied: extends
    confidence: 0.8
  grounding_count: 0
- id: embodied-decision-substrate-generation
  name: Embodied Decision Substrate Generation
  summary: Generate sufficient mock/sample data to populate decision interfaces so users can develop felt intuition 
    rather than abstract evaluation.
  description: "Generate sufficient mock/sample data to populate decision interfaces so users can develop felt intuition rather
    than abstract evaluation.\n\nRather than describing options abstractly, generate enough concrete mock data to fill out
    decision support interfaces. This enables users to develop an 'embodied feel' for what each choice entails through interaction
    with substantive content rather than evaluating descriptions of content.\n\n**When to use:** When designing decision points
    where abstract descriptions would be insufficient for users to appreciate the full weight of each option"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_synthetic_data_for_best_practi
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_embodied_decision_substrate
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: interpretive-choice-cascade-pre-computation
  name: Interpretive Choice Cascade Pre-Computation
  summary: Pre-generate the full set of downstream revisions required by each competing interpretation before presenting
    options to users.
  description: "Pre-generate the full set of downstream revisions required by each competing interpretation before presenting
    options to users.\n\nWhen users face competing interpretations of data or readings, the system pre-computes what revisions
    would be needed to interconnected elements (like throughline parts) for each option. This makes the full implications
    of each choice visible upfront rather than discovered after commitment.\n\n**When to use:** When integrating empirical
    data into structured outlines where multiple valid interpretations exist and each would propagate differently through
    the structure"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_option_impact_preview
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_interpretive_cascade_instantiation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: productivity-filtered-relationship-exploration
  name: Productivity-Filtered Relationship Exploration
  summary: Distinguish relationships that are 'productive to experiment with' from exhaustive cataloging of all possible
    connections.
  description: "Distinguish relationships that are 'productive to experiment with' from exhaustive cataloging of all possible
    connections.\n\nNot every relationship between source material and framework merits exploration. The system should help
    identify which relationships would be productive to pursue—those that might enrich, twist, or refine throughlines—based
    on current project needs rather than presenting all possible connections equally.\n\n**When to use:** When surfacing potential
    connections between sources and theoretical frameworks, to prevent overwhelm and focus experimentation."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_productive_relationship_filtering
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_resource_proportionality
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: serial-processing-with-global-throughline-awarenes
  name: Serial Processing with Global Throughline Awareness
  summary: Process source documents sequentially while maintaining active awareness of the entire throughline ecosystem.
  description: "Process source documents sequentially while maintaining active awareness of the entire throughline ecosystem.\n\
    \nWhen going through sources one by one, maintain the full context of all throughlines being developed so that each source's
    potential contributions can be evaluated against the whole system. This prevents isolated extraction and enables recognition
    of cross-throughline implications during per-document processing.\n\n**When to use:** During systematic review of source
    materials for a multi-threaded intellectual project."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_context_completeness
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_serial_global_processing
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: propagation-triggered-stress-testing
  name: Propagation-Triggered Stress Testing
  summary: Automatically trigger stress tests of interconnected system elements when modification options are surfaced.
  description: "Automatically trigger stress tests of interconnected system elements when modification options are surfaced.\n\
    \nWhen presenting virtual options for modifying one throughline, the system should automatically trigger stress tests
    showing how that modification would propagate to other throughlines. This transforms local editing decisions into system-aware
    choices by making cross-element effects visible before commitment.\n\n**When to use:** When users are considering modifications
    to any element within an interconnected argument system."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_option_impact_preview
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_bounded_propagation
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: source-framework-relationship-classification
  name: Source-Framework Relationship Classification
  summary: Explicitly categorize each source material's relationship type to the theoretical framework before 
    processing.
  description: "Explicitly categorize each source material's relationship type to the theoretical framework before processing.\n\
    \nWhen integrating external sources (PDFs, articles) with developing arguments, first classify what kind of relationship
    the source has: illustration of main dynamic, discovery of previously undetected nuance/sub-dynamic, challenge to existing
    logic, etc. Different relationship types then route to different processing pathways with distinct implications for framework
    evolution.\n\n**When to use:** When processing batches of source materials against established theoretical throughlines,
    before extracting or integrating content."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_content_based_routing
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_relationship_type_taxonomy
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: cascaded-generation-triggers
  name: Cascaded Generation Triggers
  summary: Trigger generation of dependent elements immediately after generating the elements they depend on.
  description: "Trigger generation of dependent elements immediately after generating the elements they depend on.\n\nWhen
    one element is generated, immediately trigger generation of elements that logically follow or connect to it - generate
    transitions after generating the elements they transition between, generate implementations after generating substances.
    This pre-populates the possibility space before users need to navigate it, reducing wait time during exploration.\n\n\
    **When to use:** Any workflow where elements have logical dependencies and generation is cheap enough to speculate - document
    structures where sections connect, UI flows where screens link, arguments where premises lead to conclusions."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_possibility_space_architecture
    how_embodied: Pre-generates branching possibility spaces for navigation
    confidence: 0.85
  - principle_id: prn_activity_state_gated_automation
    how_embodied: variant_of
    confidence: 0.8
  - principle_id: prn_forward_staged_data_harvesting
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: substance-instance-matrices
  name: Substance × Instance Matrices
  summary: Generate N instances per M substance types, creating a selectable matrix of possibilities.
  description: "Generate N instances per M substance types, creating a selectable matrix of possibilities.\n\nFor each archetypal
    type (substance), generate a fixed number of concrete instantiations (instances), creating an M×N matrix where users first
    select substance (choosing which archetype fits their purpose) then select instance (choosing which specific manifestation
    of that archetype they prefer). All cells are pre-generated and regeneratable.\n\n**When to use:** When presenting alternative
    approaches that vary along two dimensions: the abstract strategy (how to argue) and the concrete execution (what specific
    language to use). Examples: argument types × specific arguments, transition logics × transition phrasings."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_substance_instance_tiering
    how_embodied: Direct implementation of two-tier substance/instance selection pattern
    confidence: 0.95
  - principle_id: prn_abstract_concrete_progressive_
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_pre_curation_with_option_prese
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: collapsible-detail-architecture
  name: Collapsible Detail Architecture
  summary: Default to structural/logical summaries with expandable detailed content underneath.
  description: "Default to structural/logical summaries with expandable detailed content underneath.\n\nPresent each element
    with a two-layer structure: a visible structural summary (bulletpoints, logic description, archetypal name) and a collapsed
    detailed layer (full narrative text, specific language). Users can expand any element to see detail without leaving the
    structural overview. This preserves big-picture navigation while making concrete instantiation accessible.\n\n**When to
    use:** When users need to make structural decisions across many elements before attending to surface-level detail - essay
    structure, argument organization, narrative planning."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_format_for_decision_support
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_function_form_phase_separation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_detail_deferral_with_accessibility
    how_embodied: Implements collapsed-by-default detail with expand-on-demand access
    confidence: 0.95
  grounding_count: 0
- id: hierarchical-sharpen-triggers
  name: Hierarchical Sharpen Triggers
  summary: Regeneration buttons that incorporate all downstream selections and rejections into the regeneration context.
  description: "Regeneration buttons that incorporate all downstream selections and rejections into the regeneration context.\n\
    \nEach element has a 'sharpen' action that regenerates it using enriched context from all user choices made at downstream
    levels. The sharpening call includes not just what was selected but what was rejected, enabling the LLM to understand
    the full decision space and generate options more precisely aligned with emerging user preferences.\n\n**When to use:**
    Any system where earlier/abstract elements can be made more appropriate after later/concrete elements have been specified
    - outlines after content is drafted, introductions after conclusions are written, connectors after both endpoints are
    defined."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_regeneration_over_retrofitting
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_contrastive_context_enrichment
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_upstream_regeneration_from_downstream
    how_embodied: Enables downstream refinements to trigger upstream regeneration
    confidence: 0.95
  - principle_id: prn_refinement_versioning
    how_embodied: Tracks version numbers through iterative sharpen cycles
    confidence: 0.9
  - principle_id: prn_negative_selection_capture
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: in-slot-option-swapping
  name: In-Slot Option Swapping
  summary: Multiple options occupy the same visual position, with selection swapping content in place rather than 
    stacking alternatives.
  description: "Multiple options occupy the same visual position, with selection swapping content in place rather than stacking
    alternatives.\n\nWhen presenting multiple possibilities for an element (e.g., transition options between arguments), alternatives
    should swap into the same visual slot rather than appearing as a vertical stack. Clicking 'transition #2' replaces 'transition
    #1' in the same position, maintaining spatial relationships and making comparison feel like trying on alternatives rather
    than surveying a list.\n\n**When to use:** When presenting alternative options for any element that has a fixed position
    in a larger structure (transitions, connectors, opening variations), particularly when spatial context matters for evaluating
    fit."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_visual_state_legibility
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_format_for_decision_support
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_possibility_space_architecture
    how_embodied: Allows navigation within pre-populated option spaces
    confidence: 0.8
  grounding_count: 0
- id: logical-rhetorical-translation-prerequisites
  name: Logical-Rhetorical Translation Prerequisites
  summary: Identify features that make logical arguments more amenable to rhetorical transformation.
  description: "Identify features that make logical arguments more amenable to rhetorical transformation.\n\nBefore attempting
    to translate logical structures into rhetorical presentations, analyze which logical argument forms translate more naturally
    to effective rhetoric. Some logical arguments may need polishing to acquire features that make rhetorical transformation
    smoother—this is not rhetorical work but logical work that enables better rhetorical outcomes.\n\n**When to use:** When
    preparing structured arguments for audience-facing presentation, when evaluating whether outlines are ready for prose
    generation"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_downstream_aware_generation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_dual_outline_constraint
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_function_form_phase_separation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: bidirectional-stage-learning-loop
  name: Bidirectional Stage Learning Loop
  summary: Generate outputs at later stages to learn what's needed at earlier stages, then iterate.
  description: "Generate outputs at later stages to learn what's needed at earlier stages, then iterate.\n\nRather than perfecting
    each stage before advancing, generate provisional outputs at later stages to reveal what's missing or underdeveloped at
    earlier stages. Use the experience of producing version 1 of a later-stage output to understand what refinements are needed
    at prior stages. This creates a learning cycle where stage interdependencies are discovered empirically rather than theorized
    abstractly.\n\n**When to use:** When process design is uncertain, when stage interdependencies are unclear, or when theoretical
    analysis of stage requirements is proving unproductive"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_dialectical_refinement
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_practical_discovery_over_theoretical
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_process_as_data
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: rhetorical-gap-taxonomy
  name: Rhetorical Gap Taxonomy
  summary: Maintain an explicit classification of what might be missing for effective rhetorical presentation.
  description: "Maintain an explicit classification of what might be missing for effective rhetorical presentation.\n\nWhen
    transitioning from structural to presentational concerns, systematically check against a taxonomy of rhetorical elements:
    opening hooks, illustrative examples, clarifying metaphors, narrative landmarks/flagposts, structural interventions (chapters/parts),
    closing statements (rhetorical questions, calls to action). This taxonomy provides structured gap identification rather
    than ad-hoc noticing.\n\n**When to use:** When preparing content for rhetorical presentation, evaluating whether structural
    outlines are ready for execution, or assessing writing completeness"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_gap_aware_processing
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_benchmark_driven_best_practice
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_domain_archetypes
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: comprehensive-execution-brief
  name: Comprehensive Execution Brief
  summary: Create a self-contained document that enables a zero-context LLM to execute complex tasks.
  description: "Create a self-contained document that enables a zero-context LLM to execute complex tasks.\n\nWhen delegating
    to a new LLM session, produce a brief that contains: complete background context, explicit task specifications, success
    criteria, permitted interventions, constraints, and the rationale for decisions. The goal is immersion sufficient that
    the executing LLM can handle edge cases intelligently without consultation. This is not mere instruction but knowledge
    transfer that enables autonomous execution.\n\n**When to use:** When work must span multiple LLM sessions, when delegating
    to automated pipelines, or when human-designed plans must be machine-executed"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_context_immersion_for_execution
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_context_completeness
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cross_session_context_handoff
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: stage-bridging-extraction-strategy
  name: Stage-Bridging Extraction Strategy
  summary: Systematically identify what can be extracted at the current stage that will serve subsequent stages.
  description: "Systematically identify what can be extracted at the current stage that will serve subsequent stages.\n\n\
    At each processing stage, explicitly analyze what information could be gathered that would enable better performance at
    the next stage. Package this extraction within current-stage work so users contribute without recognizing the forward-looking
    purpose. This creates a pipeline where each stage actively prepares for its successor rather than operating in isolation.\n\
    \n**When to use:** When designing multi-stage processing pipelines, especially where user input is required at multiple
    stages and backtracking is costly"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_forward_staged_data_harvesting
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_downstream_aware_generation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_structured_elicitation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: user-question-driven-pattern-discovery
  name: User-Question-Driven Pattern Discovery
  summary: Ground pattern discovery in the specific questions target users would ask.
  description: "Ground pattern discovery in the specific questions target users would ask.\n\nThe prompt frames the entire
    analysis around \"researchers who want to make quick sense of collections of articles\" and their characteristic needs.
    This provides evaluative criteria for which patterns matter and which are merely interesting - does discovering this help
    researchers or not?\n\n**When to use:** When analyzing for system design and the ultimate measure of success is user value
    rather than analytical completeness."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_user_archetype_grounding
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_function_based_on_demand_retri
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: noise-aware-prompt-framing
  name: Noise-Aware Prompt Framing
  summary: When providing noisy data to LLMs, explicitly frame expectations about relevance and filtering.
  description: "When providing noisy data to LLMs, explicitly frame expectations about relevance and filtering.\n\nThe instruction
    to clarify that \"some of the data... won't be relevant\" preemptively calibrates LLM behavior. This prevents the model
    from either forcing relevance onto irrelevant data or becoming confused about why certain content is included.\n\n**When
    to use:** Any task where input data is not curated specifically for the analysis, including historical data, legacy systems,
    or comprehensive archives that contain mixed-relevance content."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_irrelevance_tolerance_instruction
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_wildcard_inclusion_for_complet
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: trinity-classification-framework
  name: Trinity Classification Framework
  summary: Structure analytical exploration around a multi-dimensional classification scheme that captures complementary
    aspects.
  description: "Structure analytical exploration around a multi-dimensional classification scheme that captures complementary
    aspects.\n\nThe engines/bundles/media trinity provides three lenses for classifying the same phenomena - processing logic
    (engines), organizational grouping (bundles), and output rendering (media). This multi-dimensional approach prevents premature
    collapse into a single classification axis.\n\n**When to use:** When exploring patterns in complex domains where phenomena
    have multiple aspects that may require different treatment - what something is, how it's grouped, and how it's presented."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_extrapolative_inference_request
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_provisional_structures
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: streaming-progress-visibility
  name: Streaming Progress Visibility
  summary: For long-running LLM operations, use streaming with visual progress indicators to maintain operational 
    visibility.
  description: "For long-running LLM operations, use streaming with visual progress indicators to maintain operational visibility.\n\
    \nThe mention of \"streaming, dots, etc\" indicates a pattern of maintaining visible progress for extended API calls.
    This prevents the \"black box\" effect where users don't know if processing is stalled or progressing, enabling informed
    intervention.\n\n**When to use:** Any batch or long-running LLM operation where human monitoring is expected and where
    early termination or intervention may be necessary."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_visual_state_legibility
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: context-limit-splitting-strategy
  name: Context-Limit Splitting Strategy
  summary: When source materials exceed context limits, split them strategically into multiple processing units.
  description: "When source materials exceed context limits, split them strategically into multiple processing units.\n\n\
    Rather than truncating or summarizing oversized inputs, the approach proactively identifies files that may exceed token
    limits and splits them into multiple units that each receive full-fidelity processing. \"We might need to split the largest
    of them into two if it's more than one million tokens.\"\n\n**When to use:** When working with large documents or datasets
    that may exceed model context windows, especially when fidelity of analysis matters more than processing efficiency."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_provenance_preservation
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_staged_processing
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: batch-then-synthesize-pattern
  name: Batch-Then-Synthesize Pattern
  summary: Process multiple items individually with intermediate artifacts, then perform cross-item synthesis.
  description: "Process multiple items individually with intermediate artifacts, then perform cross-item synthesis.\n\nEach
    file is processed independently, generating an analysis_[x].json artifact that captures findings. Only after all individual
    processing completes does the system perform a reconciliation synthesis across all artifacts. This creates clean separation
    between exploration and integration.\n\n**When to use:** When analyzing multiple documents or data sources for emergent
    patterns, especially when individual items may exceed what can be meaningfully processed together, or when intermediate
    artifacts enable progressive refinement."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_staged_processing
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cross_slot_synthesis_scanning
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: feat_ai_thinking_environments
  name: AI Thinking Environments
  summary: AI-mediated contexts can produce superior thinking environments compared to traditional tools by enabling 
    real-time theory testing, virtualization, simulation, and dynamic feedback that traditional writing tools cannot 
    provide.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_interactive_cognition
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_meta_learning_capability_evolution
  name: Meta-Learning Capability Evolution
  summary: Systems should include meta-learning components that analyze operational feedback and propose modifications 
    to their own capability registries, shortening the path from insight to implementation.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_self_modifying_systems
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_comprehensive_llm_context
  name: Comprehensive LLM Context
  summary: Provide comprehensive context to LLMs, even if not immediately relevant to the specific task, because 
    understanding emerges from relationships between elements rather than isolated facts.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_context_completeness
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_llm_readable_capability_registry
  name: LLM-Readable Capability Registry
  summary: System capabilities should be explicitly registered in structured schemas that LLMs can read, select from, 
    and combine—making the system's action space legible to AI reasoning.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_machine_legible_affordances
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_paradigm_schema_embodiment
  name: Paradigm Schema Embodiment
  summary: Embody coherent paradigms, epistemes, and ideologies as structured schemas within the system, enabling 
    theories to be subjected to rigorous multi-perspectival critique from various intellectual vantage points.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_perspective_as_structure
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_multi_model_cross_examination
  name: Multi-Model Cross-Examination
  summary: Use multiple LLM models to cross-examine each other's outputs and observe how they respond differently to 
    similar tasks—their divergence reveals insights and accelerates understanding of the problem domain.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_divergence_as_signal
    how_embodied: Created by refactoring engine
    confidence: 0.8
  - principle_id: prn_adversarial_multi_perspective_refinement
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_llm_dynamic_personalization
  name: LLM Dynamic Personalization
  summary: Use LLMs to generate both content and design elements dynamically, creating bespoke outputs personalized to 
    specific data and context rather than forcing contexts into generic templates.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_generative_personalization
    how_embodied: Created by refactoring engine
    confidence: 0.8
  - principle_id: prn_context_as_configuration
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: feat_budget_front_loading
  name: Budget Front-Loading
  summary: Elicit explicit resource budgets (time, queries, cost) as first-class inputs at the beginning of workflows, 
    using them to drive strategic choices rather than treating them as afterthoughts that truncate execution.
  description: ''
  project: refactoring
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_constraint_as_strategy
    how_embodied: Created by refactoring engine
    confidence: 0.8
  - principle_id: prn_front_load_decisions
    how_embodied: Created by refactoring engine
    confidence: 0.8
  grounding_count: 0
- id: future-use-injection
  name: Future-Use Injection
  summary: Explicitly inject downstream processing requirements into upstream generation prompts.
  description: "Explicitly inject downstream processing requirements into upstream generation prompts.\n\nThis technique involves
    documenting all downstream operations that will be performed on generated outputs, then incorporating those requirements
    directly into the generation prompt. For example, if throughlines will be synthesized across shared slots, the throughline
    generation prompt explicitly states this requirement so the LLM can structure outputs to facilitate that synthesis.\n\n\
    **When to use:** When designing multi-stage LLM pipelines where outputs from earlier stages feed into later processing.
    Critical when later stages have structural requirements that early-stage outputs must satisfy."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_downstream_aware_generation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_capability_addition_cascade_analysis
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: bridging-strategy-elicitation
  name: Bridging Strategy Elicitation
  summary: Explicitly request LLMs to generate strategies for connecting disparate elements rather than asking them to 
    simply connect those elements.
  description: "Explicitly request LLMs to generate strategies for connecting disparate elements rather than asking them to
    simply connect those elements.\n\nInstead of asking \"combine these throughlines,\" ask \"what bridging strategies could
    make these throughlines click together?\" This meta-level query produces actionable techniques rather than a single merged
    output, giving users strategic options and making the reconciliation logic explicit. The strategies themselves become
    artifacts that can be evaluated, selected, and reused.\n\n**When to use:** When integrating elements that have meaningful
    tensions or divergences—not simple aggregation cases but genuine synthesis challenges where the mode of integration matters."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_possibility_space
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_cognitive_load_transfer
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: slot-level-synthesis-abstraction
  name: Slot-Level Synthesis Abstraction
  summary: Generate abstract synthesis by reconciling content from multiple sources at each structural slot rather than 
    attempting holistic integration.
  description: "Generate abstract synthesis by reconciling content from multiple sources at each structural slot rather than
    attempting holistic integration.\n\nRather than synthesizing entire documents or arguments at once, this technique processes
    each functional slot (e.g., IMPLICATIONS) independently across all source streams. For each slot, the LLM identifies shared
    points, reconciles tensions, and produces a unified abstraction. This produces synthesis that respects the structural
    logic of the domain while managing the cognitive complexity of integration.\n\n**When to use:** When merging multiple
    documents, arguments, or analyses that share common structural slots. Especially useful when sources have natural alignment
    through shared templates but divergent content within those templates."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cross_slot_synthesis_scanning
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: throughline-factory-pattern
  name: Throughline Factory Pattern
  summary: A structured approach to generating multiple parallel argument streams that share common functional slots and
    are designed for eventual convergence.
  description: "A structured approach to generating multiple parallel argument streams that share common functional slots
    and are designed for eventual convergence.\n\nThe pattern involves generating multiple independent \"throughlines\" (argument
    threads) that each populate the same structural skeleton. Each throughline has its own content for shared slots (IMPLICATIONS,
    INTERVENTIONS, etc.), but the slot structure is common across all throughlines. This shared structure enables systematic
    synthesis at each slot level when throughlines are merged.\n\n**When to use:** When building systems that generate multiple
    parallel options (arguments, designs, analyses) that must eventually be synthesized rather than simply selected between.
    Particularly valuable when the synthesis should preserve elements from multiple streams rather than choosing one winner."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_downstream_aware_generation
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_shared_scaffold_parallel_streams
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cascading_virtuality
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: recommendation-mode-request
  name: Recommendation Mode Request
  summary: "Explicitly request that the LLM propose a default recommendation rather than presenting balanced analysis.\n"
  description: "Explicitly request that the LLM propose a default recommendation rather than presenting balanced analysis.\n\
    \n\nThe prompt design goal is that the LLM \"would propose a default and we won't have to think about it ourselves.\"\
    \ This represents a specific output mode— recommendation rather than analysis—that must be explicitly requested because
    LLMs often default to presenting balanced considerations. Framing expectations around \"propose a default\" shifts the
    output from neutral to advisory.\n\n\n**When to use:** Apply when the human role is to approve, override, or refine rather
    than to synthesize from scratch. Particularly valuable for routine decisions where cognitive effort should be minimized
    but human authority preserved.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cognitive_load_transfer
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_default_recommendation_elicitation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: criteria-enumeration-in-advisory-prompts
  name: Criteria Enumeration in Advisory Prompts
  summary: "Explicitly name the evaluation criteria when requesting decision advice from LLMs.\n"
  description: "Explicitly name the evaluation criteria when requesting decision advice from LLMs.\n\n\nThe prompt specifies
    asking \"which would better serve our need for abstraction, modularity, comprehensiveness\"—naming the criteria rather
    than asking for general advice. This technique makes the grounds for recommendation explicit, ensures the LLM reasons
    about what actually matters, and makes recommendations auditable against stated criteria.\n\n\n**When to use:** Apply
    whenever requesting comparative evaluation or decision advice, especially when the relevant criteria are domain-specific
    or non-obvious. Critical when recommendations will influence downstream processing or persistent structures.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_comprehensive_context
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_context_completeness
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_criteria_grounded_advisory
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: choice-architecture-constraint
  name: Choice Architecture Constraint
  summary: "Frame advisory requests by explicitly stating the choice architecture (\"if the choice is between X and Y\") to
    bound the response space.\n"
  description: "Frame advisory requests by explicitly stating the choice architecture (\"if the choice is between X and Y\"\
    ) to bound the response space.\n\n\nRather than asking open-ended \"what should I do?\" questions, the prompt frames the
    decision as \"if the choice is between linking it to this existing principle or creating a new one.\" This constrains
    the LLM's advisory space to the actual options under consideration, preventing tangential advice about options not on
    the table.\n\n\n**When to use:** Apply when the decision space is already known and the need is for comparative evaluation
    rather than option discovery. Particularly useful when prior processing has already established what the viable options
    are.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_criteria_grounded_advisory
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_format_for_decision_support
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: two-stage-generation-advice-pattern
  name: Two-Stage Generation-Advice Pattern
  summary: "Separate option generation from selection advice into distinct, sequential API calls.\n"
  description: "Separate option generation from selection advice into distinct, sequential API calls.\n\n\nThe first API call
    focuses purely on generating the possibility space—in this case, identifying which existing principles could serve as
    parents for a demoted feature, plus surfacing the option of creating new principles. The second API call takes this generated
    space as input and provides advisory output on selection. This separation allows each call to be optimized for its function.\n\
    \n\n**When to use:** Apply when a workflow requires both creative option generation and evaluative selection guidance,
    particularly when the evaluation criteria are complex enough to benefit from dedicated reasoning rather than post-hoc
    filtering.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_generation_evaluation_separation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_deferred_selection
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: assumption-grounded-question-sequencing
  name: Assumption-Grounded Question Sequencing
  summary: Sequence questions so that later questions only build on verified earlier answers.
  description: "Sequence questions so that later questions only build on verified earlier answers.\n\nMap the dependency structure
    of questions—which questions assume answers to other questions. Sequence interrogation so that assumption-generating questions
    come before assumption-dependent questions, and generate later questions only after earlier dependencies are resolved.
    Never stack questions on unverified foundations.\n\n**When to use:** Multi-stage elicitation where questions have logical
    dependencies—diagnostic workflows, requirements refinement, philosophical inquiry, essay premise development."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_logical_coherence
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_assumption_dependency_management
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_front_load_decisions
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: llm-deputized-exploration-pattern
  name: LLM-Deputized Exploration Pattern
  summary: Delegate possibility space exploration to LLM, reserve human attention for selection.
  description: "Delegate possibility space exploration to LLM, reserve human attention for selection.\n\nRather than asking
    users to generate options or articulate positions from scratch, have the LLM exhaustively enumerate the possibility space
    based on context, then present these as options for human evaluation. This exploits the asymmetry between LLM generation
    costs (cheap) and human generation costs (expensive/fatiguing).\n\n**When to use:** Any scenario where users \"know it
    when they see it\" better than they can generate it from scratch—design preference elicitation, problem framing, strategic
    option development, assumption mapping."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cognitive_load_transfer
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_anthropologist_role
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_possibility_space
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: progressive-batch-interrogation-pattern
  name: Progressive Batch Interrogation Pattern
  summary: Present questions in small batches, adapting subsequent batches based on answers.
  description: "Present questions in small batches, adapting subsequent batches based on answers.\n\nInstead of presenting
    all questions upfront, divide interrogation into stages (e.g., 3 batches of 3 questions). Each batch generates based on
    prior answers plus remaining strategic objectives. The final batch synthesizes everything from earlier stages. Accept
    latency between batches as the cost of relevance.\n\n**When to use:** Complex elicitation scenarios where later questions
    should depend on earlier answers—onboarding flows, diagnostic interviews, requirements gathering, assumption refinement
    for creative work."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_emergence_through_iterative_re
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_staged_adaptive_interrogation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: multiple-choice-with-escape-valve-pattern
  name: Multiple-Choice with Escape Valve Pattern
  summary: Generate N structured options plus one open-ended "add your own" option.
  description: "Generate N structured options plus one open-ended \"add your own\" option.\n\nPre-generate sophisticated multiple
    choice answers (e.g., 5) that represent the LLM's best mapping of the possibility space, then add a final option for user-generated
    alternatives. This captures 80% of cases efficiently while preserving 100% coverage through the escape valve. Allow multiple
    selections to reflect that preferences aren't always mutually exclusive.\n\n**When to use:** Any user input solicitation
    where the domain is bounded enough for meaningful option generation but open enough that surprises are possible—preference
    elicitation, assumption probing, configuration selection, feedback collection."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cognitive_load_transfer
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_possibility_space
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_wildcard_inclusion_for_complet
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: genre-indexed-requirement-templates
  name: Genre-Indexed Requirement Templates
  summary: Use genre conventions to pre-specify what functional elements and through-lines a piece needs, guiding the 
    elicitation process.
  description: "Use genre conventions to pre-specify what functional elements and through-lines a piece needs, guiding the
    elicitation process.\n\nFor each genre (essay, analysis, proposal, etc.), the system maintains a template of expected
    functional slots and common through-line patterns. This allows the system to \"coach and force and nudge the user into
    thinking about dimensions that they need to think through\" by knowing in advance what building blocks are typically required.\n\
    \n**When to use:** Apply when the output genre is known and has conventional structural expectations that can scaffold
    the elicitation and composition process."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_domain_archetypes
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_genre_as_scaffold
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_benchmark_driven_best_practice
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: phase-readiness-gates
  name: Phase Readiness Gates
  summary: Transitions between processing phases require explicit verification that prior phases have achieved 
    sufficient completion.
  description: "Transitions between processing phases require explicit verification that prior phases have achieved sufficient
    completion.\n\nThe system tracks \"readiness\" for phase transitions—e.g., rhetorical outlining is gated until the functional
    outline reaches sufficient completeness. Gates can be surfaced to users as prompts (\"We need X more elements before we
    can identify through-lines\") and can be overridden with user acknowledgment of the limitations this introduces.\n\n**When
    to use:** Apply in multi-phase workflows where later phases depend on the outputs of earlier phases and premature transition
    would produce hollow results."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_abstraction_level_sequencing
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: theory-answer-multiplication
  name: Theory-Answer Multiplication
  summary: User inputs are systematically combined with a persistent theoretical framework to generate strategic items 
    that neither could produce alone.
  description: "User inputs are systematically combined with a persistent theoretical framework to generate strategic items
    that neither could produce alone.\n\nRather than processing user answers in isolation, the system routes them through
    an existing theoretical base extracted from the user's prior work. This enables inference, reveals implications, surfaces
    connections, and generates follow-up questions that wouldn't emerge from the answers alone. Strategic items are tagged
    with both their input origin and theoretical grounding.\n\n**When to use:** Apply when users have an existing body of
    work or theoretical commitments that should inform the interpretation of new inputs."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_intellectual_profile
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_theory_grounded_extraction
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cross_pollination_as_generativ
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: through-line-factory-pattern
  name: Through-line Factory Pattern
  summary: An explicit scanning mechanism that identifies potential higher-level connections across disparate functional
    elements.
  description: "An explicit scanning mechanism that identifies potential higher-level connections across disparate functional
    elements.\n\nA dedicated processing component that takes a populated functional outline and systematically scans for patterns
    that could constitute through-lines—abstract connective tissues linking different parts of an argument (e.g., diagnosis
    to prescription, phenomena to implications). The factory both proposes candidate through-lines and identifies what elements
    are missing to complete them.\n\n**When to use:** Apply after functional elements are sufficiently populated, as a distinct
    phase that bridges component-level and synthesis-level work."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_gap_aware_processing
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_cross_slot_synthesis_scanning
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: question-to-problematique-conversion
  name: Question-to-Problematique Conversion
  summary: A mechanism to convert unanswered questions into deliberately preserved dialectical tensions rather than 
    treating them as blockers.
  description: "A mechanism to convert unanswered questions into deliberately preserved dialectical tensions rather than treating
    them as blockers.\n\nWhen users cannot answer follow-up questions, the system offers to convert them to \"problematiques\"\
    —marked open questions that become structural features of the output. These are tracked separately from gaps-to-be-filled,
    and can be surfaced in the final argument as acknowledged uncertainties or dialectical tensions.\n\n**When to use:** Apply
    when building knowledge structures where some uncertainty is legitimate and should be preserved in the output, rather
    than hidden or artificially resolved."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_productive_incompletion
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_optionality_preservation
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: mutual-exclusivity-mapping
  name: Mutual Exclusivity Mapping
  summary: Explicitly identify and display which possibilities are mutually exclusive versus composable.
  description: "Explicitly identify and display which possibilities are mutually exclusive versus composable.\n\nWhen generating
    multiple possibilities, analyze and mark which options can coexist (can be combined into the same throughline/configuration)
    versus which are mutually exclusive (choosing one eliminates others). This transforms a flat list of options into a structured
    possibility space with explicit constraints.\n\n**When to use:** When presenting options that have logical relationships
    with each other—some compatible, some incompatible—and users need to understand these relationships to make informed choices."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_logical_coherence
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_possibility_as_foreclosure_warning
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_contrastive_context_enrichment
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: ui-llm-complementarity-architecture
  name: UI-LLM Complementarity Architecture
  summary: Design UI and LLM as complementary systems with distinct roles in managing possibility space.
  description: "Design UI and LLM as complementary systems with distinct roles in managing possibility space.\n\nStructure
    the system so that UI handles presentation, selection, and state management while LLM handles generation, questioning,
    and possibility analysis. Both are \"allies\" working toward the same goal of surfacing and exploring options. UI makes
    possibilities navigable; LLM makes possibilities visible. Neither alone is sufficient.\n\n**When to use:** When building
    AI-augmented tools where users need to both explore generated options and make consequential selections among them."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_thinking_environments
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_interactive_cognition
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_format_for_decision_support
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: functional-slot-architecture
  name: Functional Slot Architecture
  summary: Define argument structure through named functional positions rather than content-based or positional 
    descriptions.
  description: "Define argument structure through named functional positions rather than content-based or positional descriptions.\n\
    \nDecompose arguments (or other complex artifacts) into functional slots like \"diagnosis,\" \"implication,\" \"intervention\"\
    \ where each slot is defined by what it DOES in the argument rather than what it contains or where it appears. Content
    can then be assigned to slots based on functional fit, and the same content might serve different functions in different
    configurations.\n\n**When to use:** When building systems for argument construction, essay writing, or any structured
    composition where the role of elements matters more than their position or identity."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_trajectory_over_identity
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_function_form_phase_separation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_genre_as_scaffold
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: llm-driven-diagnostic-questioning
  name: LLM-Driven Diagnostic Questioning
  summary: LLM identifies what it can see, what's uncertain, and what questions would resolve uncertainty.
  description: "LLM identifies what it can see, what's uncertain, and what questions would resolve uncertainty.\n\nRather
    than generating complete outputs or asking generic questions, the LLM analyzes its current understanding, identifies specific
    gaps or decision points where user input would materially change outputs, and generates targeted questions. The questions
    are diagnostically motivated—each question has a clear function in the possibility space.\n\n**When to use:** When user
    input is incomplete or ambiguous and the LLM can identify specific information that would disambiguate between competing
    possibilities."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_anthropologist_role
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_proactive_insufficiency_signaling
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_emergence_through_iterative_re
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: multi-level-possibility-mapping-interface
  name: Multi-Level Possibility Mapping Interface
  summary: Generate and display possibilities at multiple abstraction levels with explicit mapping between levels.
  description: "Generate and display possibilities at multiple abstraction levels with explicit mapping between levels.\n\n\
    Create a UI pattern where possibilities exist at distinct abstraction layers (e.g., strategic items → throughlines → slots),
    and the interface explicitly shows how possibilities at one level combine to produce possibilities at the next. Users
    can explore combinations and see which upstream choices generate which downstream option spaces.\n\n**When to use:** When
    building systems for complex artifacts (arguments, designs, plans) that have hierarchical structure where decisions at
    higher levels constrain options at lower levels."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_possibility_space
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cascading_virtuality
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_visual_state_legibility
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: state-contrast-audit
  name: State Contrast Audit
  summary: Verify that all interactive states have sufficient visual differentiation.
  description: "Verify that all interactive states have sufficient visual differentiation.\n\nSystematically enumerate the
    visual states an interface element can inhabit (active/inactive, selected/unselected, hovered, disabled) and verify that
    each pair of states has sufficient contrast to be instantly distinguishable. Flag state pairs that rely on subtle differences
    (slight opacity changes, minor color shifts) as legibility risks requiring remediation.\n\n**When to use:** Interface
    design review, accessibility auditing, any system where users make selections that will inform downstream LLM processing."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_visual_state_legibility
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: decision-support-formatting
  name: Decision-Support Formatting
  summary: Transform LLM outputs requiring user selection into visually structured, scannable formats.
  description: "Transform LLM outputs requiring user selection into visually structured, scannable formats.\n\nWhen LLM outputs
    will be presented for human evaluation/selection, apply formatting transforms that prioritize comparison: convert prose
    lists to bulleted items, separate options with visual boundaries, group related items, ensure consistent structure across
    alternatives. This is a distinct formatting mode from 'reading comprehension' presentation.\n\n**When to use:** Any interface
    where users must choose among LLM-generated options—cluster selection, alternative generation, recommendation surfaces,
    classification review."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_bespoke_contextual
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_format_for_decision_support
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_generative_personalization
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: decision-context-bundle
  name: Decision Context Bundle
  summary: Package selections with their decision context for downstream LLM consumption.
  description: "Package selections with their decision context for downstream LLM consumption.\n\nWhen users make selections,
    construct a structured bundle containing: (1) what options were available, (2) what was selected, (3) what was explicitly
    viewed but not selected, (4) optionally, the sequence of interaction. Pass this bundle to downstream LLM processing stages
    rather than just the selection results. Format enables LLM to reason about user preferences contrastively.\n\n**When to
    use:** Multi-stage workflows where early human selections inform later LLM processing—wizard interfaces, iterative refinement
    flows, preference elicitation systems."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_negative_selection_capture
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_decision_space_propagation
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_contrastive_context_enrichment
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: quiescence-triggered-automation
  name: Quiescence-Triggered Automation
  summary: Gate automated actions on detected user inactivity rather than immediate event response.
  description: "Gate automated actions on detected user inactivity rather than immediate event response.\n\nMonitor user activity
    signals (mouse movement, clicking patterns, scroll behavior) and only trigger automated behaviors (navigation, suggestions,
    updates) when the user has been quiescent for a threshold period. This transforms automation from chaotic interruption
    into assistive suggestion that respects the user's exploration rhythm.\n\n**When to use:** Any interface where automated
    suggestions or navigation could interrupt active user exploration—auto-complete, smart navigation, recommendation surfaces,
    contextual help."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_activity_state_gated_automation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: edit-impact-tracking
  name: Edit Impact Tracking
  summary: Shows ripple effects when editing a slot, displaying affected throughlines, strategic items, and rhetorical 
    sections.
  description: 'When a user edits a functional slot, displays a cascade impact preview showing: affected throughlines that
    span this slot, linked strategic items, rhetorical sections that draw from this slot. Offers options to update all downstream
    references, park affected items for manual review, or proceed without cascade. Prevents unintended inconsistencies from
    isolated edits.'
  project: essay-flow
  confidence: 0.85
  status: draft
  principles:
  - principle_id: prn_controlled_propagation
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_cascade_containment
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_logical_coherence
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: reasoning-chain-display
  name: Reasoning Chain Display
  summary: Shows the analytical reasoning that led to each suggested option, not just the options themselves.
  description: When presenting thesis options or slot suggestions, displays HOW each emerged from the user's material. 
    Shows which passages supported the inference, what analytical moves were made (synthesis of contradictions, 
    contrarian reframing, etc.), and confidence levels with justification. Users understand the analytical work that 
    produced options rather than receiving them as unexplained alternatives.
  project: essay-flow
  confidence: 0.85
  status: draft
  principles:
  - principle_id: prn_emergent_choice
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_formalization_as_education
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: critical-question-prioritization
  name: Critical Question Prioritization
  summary: Dynamically reorders questionnaire questions to front-load the most consequential ones based on genre.
  description: The entry questionnaire reorders itself based on what's most consequential for the selected genre. For 
    Book Review, thesis and phenomenon come first. For Political Analysis, diagnosis might lead. Questions are marked 
    with priority indicators (★) and users see an explanation of why certain questions come first ("Questions 1-2 
    determine all downstream answers"). Ensures path-dependent decisions are made early.
  project: essay-flow
  confidence: 0.85
  status: draft
  principles:
  - principle_id: prn_genre_as_scaffold
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_front_load_decisions
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: slot-saturation-detection
  name: Slot Saturation Detection
  summary: Tracks material density per functional slot and suggests when users have enough content to move to the next 
    phase.
  description: Adds a "Coverage Meter" that monitors how much material has been collected for each functional slot. 
    Shows saturation percentages, flags underdeveloped slots, and actively suggests when the user should stop collecting
    and start structuring. Provides contextual guidance like "You have strong diagnostic material but weak implications 
    - consider adding consequences before moving to rhetorical sequencing."
  project: essay-flow
  confidence: 0.9
  status: draft
  principles:
  - principle_id: prn_adaptive_termination
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_gap_aware_processing
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: translation-map-display
  name: Translation Map Display
  summary: Shows users how their raw notes mapped to functional slots during analysis, making structural translation 
    visible and educational.
  description: When Notes Import analyzes user text, displays a "Translation Map" panel showing the mapping between 
    original text passages and the functional slots they were assigned to, along with confidence scores. Users see 
    exactly WHY their notes became specific slots (PHENOMENON, DIAGNOSIS, etc.), learning the essay structure through 
    use. This transforms the analysis from a black box into a teaching moment.
  project: essay-flow
  confidence: 0.9
  status: draft
  principles:
  - principle_id: prn_tacit_to_explicit
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_formalization_as_education
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: cost-explained-processing-choice
  name: Cost-Explained Processing Choice
  summary: Presenting users with processing strategy choices alongside explicit cost implications.
  description: "Presenting users with processing strategy choices alongside explicit cost implications.\n\nWhen offering users
    the choice between pre-extraction (batch processing all types upfront) and on-demand extraction (processing as needed),
    the system 'explains clearly' the cost implications of each approach. This pattern makes resource tradeoffs visible and
    gives users informed agency over computational expenditure rather than hiding costs or making unilateral decisions.\n\n\
    **When to use:** When systems offer multiple processing strategies with different resource profiles, especially in LLM-based
    systems where token costs vary significantly based on approach."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_constraint_as_strategy
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_budget_driven_strategy
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_dual_mode_operation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: expert-transparency-mode
  name: Expert Transparency Mode
  summary: An optional detailed view that exposes internal processing logic for users developing expertise.
  description: "An optional detailed view that exposes internal processing logic for users developing expertise.\n\nFor 'expert
    users, or users who are about to become experts,' the system provides a way to 'go and look inside the hood, but in an
    accessible way.' This view shows what each visualization mode extracts, how elements pass to the curator, and how different
    modes affect processing. The feature serves both transparency and pedagogical goals—building user mental models of previously
    black-box processes.\n\n**When to use:** When building systems with pedagogical goals where users should progressively
    understand system internals, or when transparency is valued for trust-building with sophisticated users."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_formalization_as_education
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_tacit_to_explicit
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: plain-language-registry-extension-pipeline
  name: Plain-Language Registry Extension Pipeline
  summary: A multi-stage process enabling users to add new capability types through plain-language descriptions that get
    progressively formalized.
  description: "A multi-stage process enabling users to add new capability types through plain-language descriptions that
    get progressively formalized.\n\nUsers describe desired new visualization types in plain language. An LLM analyzes and
    formalizes the description. Users review the formalization, learning from the translation. Upon approval, another LLM
    creates the proper registry entry. The system then analyzes implications for extraction, curation, and rendering stages.
    This pipeline democratizes system extension while maintaining structural integrity.\n\n**When to use:** When building
    extensible systems where non-technical users should be able to add new processing modes or capability types without direct
    code modification."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_formalization_as_education
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_capability_addition_cascade_analysis
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: vision-model-output-verification-stage
  name: Vision-Model Output Verification Stage
  summary: An optional post-rendering verification step that sends generated visuals to vision-capable LLMs to confirm 
    specification adherence.
  description: "An optional post-rendering verification step that sends generated visuals to vision-capable LLMs to confirm
    specification adherence.\n\nAfter diagrams or visualizations are rendered, the system can optionally send them to vision-capable
    models (Claude, Gemini) to verify that all specified elements are present and correctly represented. This creates a quality
    assurance loop that catches rendering failures and specification drift. The feature is positioned as trust-enhancing and
    user-optional.\n\n**When to use:** When generating visual outputs where correctness is important and the generation process
    may introduce errors or omissions not detectable by the generating system alone."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_multimodal_output_verification
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_cybernetic_correction
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: extract-curate-render-pipeline
  name: Extract-Curate-Render Pipeline
  summary: A three-stage processing architecture for transforming text into visualizations with distinct LLM roles at 
    each stage.
  description: "A three-stage processing architecture for transforming text into visualizations with distinct LLM roles at
    each stage.\n\nThe workflow separates extraction (pulling elements from source texts), curation (preparing and organizing
    extracted elements for rendering), and rendering (generating final visual outputs). Each stage has dedicated prompts and
    processing logic, with outputs from each stage feeding the next. This separation enables stage-specific optimization and
    debugging.\n\n**When to use:** When building systems that transform unstructured input into structured visual outputs,
    especially when the transformation requires multiple interpretive steps that benefit from different prompting strategies."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_process_determinism
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: context-complete-session-briefing
  name: Context-Complete Session Briefing
  summary: Generate comprehensive handoff documents that contain all context needed for contextually isolated future 
    sessions.
  description: "Generate comprehensive handoff documents that contain all context needed for contextually isolated future
    sessions.\n\nWhen work must continue in a session that 'won't have any context apart from what you give it,' generate
    a complete briefing that explains: the task, the existing artifacts (prompts, pipelines), the methodology, the specific
    problem being addressed, and the desired approach. The briefing should enable a fresh session to continue work without
    information loss.\n\n**When to use:** Apply when complex multi-session work involves LLMs that lack persistent memory,
    especially when continuing sessions may use different models or occur after significant time gaps."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cross_session_context_handoff
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_comprehensive_context
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_context_completeness
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: abstract-structural-placeholder-pattern
  name: Abstract Structural Placeholder Pattern
  summary: Maintain generic structural placeholders throughout intermediate processing, reserving meaningful labels for 
    final stages.
  description: "Maintain generic structural placeholders throughout intermediate processing, reserving meaningful labels for
    final stages.\n\nUse placeholders like 'Level 0', 'Root Category', 'Sub-Category' throughout extraction and curation,
    explicitly acknowledging these are structural roles rather than content descriptions. This pattern prevents premature
    concretization while maintaining clear structural relationships. The 'robotic legend' is a feature of intermediate artifacts,
    not a bug—it signals where concretization is still needed.\n\n**When to use:** Apply when building visualization or document
    pipelines where structural relationships are determined before content fully crystallizes. Placeholders make explicit
    what remains to be concretized."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_abstract_concrete_progressive_
    how_embodied: enables
    confidence: 0.8
  - principle_id: prn_late_binding_semantic_labels
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: multi-stage-suggestion-collection-with-late-reconc
  name: Multi-Stage Suggestion Collection with Late Reconciliation
  summary: Collect naming/labeling suggestions across multiple early stages, then reconcile them in a dedicated later 
    stage.
  description: "Collect naming/labeling suggestions across multiple early stages, then reconcile them in a dedicated later
    stage.\n\nRather than making naming decisions at each stage, extraction and curation stages generate suggestions for concrete
    labels. These suggestions accumulate and are passed to a reconciliation stage that 'will look at them and reconcile or
    choose its own.' This pattern separates suggestion generation from decision-making, enabling each stage to contribute
    observations without bearing commitment burden.\n\n**When to use:** Apply when multiple processing stages have partial
    visibility into what good labels/names might be, but none has complete context. The reconciliation stage can weigh suggestions
    against each other and against the fully assembled content."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_deferred_commitment
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_optionality_preservation
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: concretization-stage
  name: Concretization Stage
  summary: A dedicated pre-rendering stage that transforms abstract structural categories into content-appropriate 
    concrete labels.
  description: "A dedicated pre-rendering stage that transforms abstract structural categories into content-appropriate concrete
    labels.\n\nAfter curation establishes logical structure and before rendering produces visual output, a concretization
    stage examines the actual content of extractions and determines appropriate semantic labels. This stage bridges abstract
    frameworks with particular content, replacing generic placeholders like 'Root Category' with meaningful names derived
    from the actual material.\n\n**When to use:** Apply when pipelines use abstract structural roles (parent/child, root/leaf,
    category/subcategory) that must eventually be presented to users with meaningful labels. Especially valuable when the
    same structural role may need different names depending on content."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_late_binding_semantic_labels
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_particularity_recovery
    how_embodied: enables
    confidence: 0.8
  grounding_count: 0
- id: carryover-relationship-annotation
  name: Carryover Relationship Annotation
  summary: Explicitly track which relationships are inherited versus directly established.
  description: "Explicitly track which relationships are inherited versus directly established.\n\nWhen relationships propagate
    through connection chains (e.g., groundings → features → principles), annotate inherited relationships distinctly from
    direct relationships. This preserves provenance and enables reasoning about relationship strength and directness.\n\n\
    **When to use:** Complex knowledge graphs with transitive relationships, provenance-sensitive systems, contexts where
    relationship strength matters."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_controlled_propagation
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_provenance_preservation
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: stray-element-as-workflow-trigger
  name: Stray Element as Workflow Trigger
  summary: Use the presence of disconnected elements as an automatic trigger for reconciliation workflows.
  description: "Use the presence of disconnected elements as an automatic trigger for reconciliation workflows.\n\nRather
    than waiting for users to notice gaps, systematically identify elements lacking expected connections and use their existence
    to initiate structured reconciliation processes. The 'stray' status becomes a first-class trigger event, not just a passive
    state.\n\n**When to use:** Knowledge graph maintenance, continuous integration of knowledge systems, any system where
    connectivity is a quality metric."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_event_driven_refinement
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_gap_aware_processing
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: zero-modification-first-assessment
  name: Zero-Modification-First Assessment
  summary: Assess whether elements can connect without changes before proposing any modifications.
  description: "Assess whether elements can connect without changes before proposing any modifications.\n\nBefore triggering
    reformulation logic, explicitly check whether the elements can be legitimately connected in their current form. This separates
    'discovery of existing but unrecognized relationships' from 'creation of new relationships through reformulation' - two
    conceptually distinct operations.\n\n**When to use:** Knowledge management systems, relationship discovery tools, any
    context where you want to distinguish finding versus creating connections."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_resource_proportionality
    how_embodied: supports
    confidence: 0.8
  - principle_id: prn_graduated_intervention_intensity
    how_embodied: embodies
    confidence: 0.8
  grounding_count: 0
- id: bidirectional-reformulation-options
  name: Bidirectional Reformulation Options
  summary: Present modification options for either or both elements when proposing relationship-enabling changes.
  description: "Present modification options for either or both elements when proposing relationship-enabling changes.\n\n\
    When an LLM proposes reformulations to enable relationships, it generates separate options: modify element A only, modify
    element B only, or modify both. This prevents hidden bias toward modifying one element type and gives users genuine choice
    about where conceptual change should occur.\n\n**When to use:** Knowledge graph curation, ontology alignment, schema reconciliation
    - any context where disconnected elements might be reconnected through semantic modification."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_bidirectional_modification_symmetry
    how_embodied: embodies
    confidence: 0.8
  - principle_id: prn_optionality_preservation
    how_embodied: supports
    confidence: 0.8
  grounding_count: 0
- id: staged-integration-workflow
  name: Staged Integration Workflow
  summary: "A multi-phase workflow moving from discovery through assessment to proposal to acceptance to integration, with
    clear gates between phases.\n"
  description: "A multi-phase workflow moving from discovery through assessment to proposal to acceptance to integration,
    with clear gates between phases.\n\n\nThe workflow explicitly sequences: (1) identification of candidates, (2) LLM assessment
    of direct compatibility, (3) LLM proposal of modifications for incompatible pairs, (4) user review and acceptance, (5)
    integration of accepted changes. Each phase has distinct inputs, outputs, and actors (system, LLM, human). The phases
    create natural breakpoints where users can pause, review, or abandon without corrupting system state.\n\n\n**When to use:**
    Apply when building any human-AI collaborative workflow where actions have persistent effects on shared data structures.
    The pattern prevents cascading errors by ensuring human checkpoints before state changes, while still leveraging LLM capability
    for discovery and proposal generation.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: reformulation-suggestion-pipeline
  name: Reformulation Suggestion Pipeline
  summary: "A workflow where an LLM proposes element modifications that would enable previously impossible relationships,
    presented for human review and selective acceptance.\n"
  description: "A workflow where an LLM proposes element modifications that would enable previously impossible relationships,
    presented for human review and selective acceptance.\n\n\nWhen direct relationship matching fails, the system enters a
    reformulation mode where the LLM generates specific suggestions for how to modify the wording, scope, or framing of elements
    such that they become compatible. These suggestions are presented as options (\"producing options for reconciliation\"\
    ) that preserve user agency. The pipeline separates generation (LLM) from selection (human), maintaining human authority
    over knowledge structure changes.\n\n\n**When to use:** Apply when knowledge structures have rigidity that prevents relationship
    formation, but the underlying concepts could be compatible with different articulation. Useful in collaborative knowledge
    building where different contributors may have expressed related ideas in incompatible framings.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: llm-mediated-relationship-proposal
  name: LLM-Mediated Relationship Proposal
  summary: "Using an LLM to assess potential relationships between elements and propose connections with varying degrees of
    modification required.\n"
  description: "Using an LLM to assess potential relationships between elements and propose connections with varying degrees
    of modification required.\n\n\nThe LLM receives two sets of disconnected elements and performs two types of analysis:
    (1) \"direct hits\" where relationships can be established without modifying either element, and (2) \"bridge proposals\"\
    \ where the LLM suggests modifications to one or both elements that would enable a valid relationship. The LLM acts as
    a semantic similarity engine with creative reformulation capability, not just a classifier.\n\n\n**When to use:** Apply
    when building systems that need to discover implicit relationships in knowledge structures, particularly when the relationship
    criteria involve semantic compatibility rather than exact matching. Effective when human time for manual relationship
    discovery is limited but the knowledge structure benefits from denser connections.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: review-accept-integrate-flow
  name: Review-Accept-Integrate Flow
  summary: Present system proposals for human review with direct pathways to integration upon acceptance.
  description: "Present system proposals for human review with direct pathways to integration upon acceptance.\n\nStructure
    the UI so that LLM-generated proposals (direct matches or reformulations) are presented for explicit human review. Acceptance
    triggers automatic integration into the knowledge base. Rejection returns to proposal generation or terminates. This pattern
    maintains human authority while minimizing friction for approved changes.\n\n**When to use:** Apply whenever system proposals
    would modify persistent knowledge structures. Essential for maintaining trust in automated systems while enabling efficient
    knowledge base evolution."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: reformulation-option-generation
  name: Reformulation Option Generation
  summary: Generate modified versions of elements specifically designed to enable new relationships.
  description: "Generate modified versions of elements specifically designed to enable new relationships.\n\nWhen elements
    don't naturally connect, prompt the LLM to produce reformulated versions—of one or both elements—that would create valid
    pairings. Present these as options with clear indication of what changed and why. This makes the LLM a collaborator in
    knowledge base improvement, not just a classifier.\n\n**When to use:** Apply after direct matching has been attempted
    and failed. Use when element definitions are provisional and the goal is knowledge base coherence rather than preserving
    original formulations."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: llm-mediated-relationship-assessment
  name: LLM-Mediated Relationship Assessment
  summary: Use an LLM to evaluate whether disconnected elements could or should be connected.
  description: "Use an LLM to evaluate whether disconnected elements could or should be connected.\n\nPosition the LLM as
    an intelligent assessor between orphaned elements and potential relationships. The LLM evaluates semantic compatibility,
    identifies near-matches, and distinguishes between 'no valid connection' and 'connection possible with modification.'
    This leverages LLM comprehension without ceding decision authority.\n\n**When to use:** Apply when orphan elements are
    identified and human review of all possible pairings would be prohibitively expensive. The LLM pre-filters and prioritizes
    human attention."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: stray-element-discovery
  name: Stray Element Discovery
  summary: Systematically identify elements lacking expected connections within a knowledge graph.
  description: "Systematically identify elements lacking expected connections within a knowledge graph.\n\nQuery the knowledge
    base to surface elements that exist in isolation—lacking connections to complementary element types. This transforms implicit
    gaps into explicit work items, making invisible incompleteness visible and actionable.\n\n**When to use:** Apply during
    knowledge base maintenance cycles, when preparing for relationship enrichment work, or when auditing knowledge structure
    integrity."
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: cascading-relationship-inheritance
  name: Cascading Relationship Inheritance
  summary: When elements link, their existing relationships propagate to connected elements.
  description: "When elements link, their existing relationships propagate to connected elements.\n\nThe prompt notes that
    \"any groundings relationships that features have  will carry on to the principles linked to features.\" This is a pattern\
    \  where establishing a new relationship causes existing relationships of  one element to propagate to the newly connected
    element. It treats  relationship creation as a trigger for inheritance propagation rather  than an isolated event.\n\n\
    \n**When to use:** Apply when knowledge elements exist in a typed relationship network where  certain relationship types
    should transitively propagate across new  connections, enabling efficient knowledge enrichment through linking.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: user-gated-integration-pattern
  name: User-Gated Integration Pattern
  summary: Staging proposed changes for review before committing to persistent structures.
  description: "Staging proposed changes for review before committing to persistent structures.\n\nA workflow pattern where
    system-generated modifications are staged in a  review space rather than directly applied. Users see proposed changes\
    \  alongside their implications, can accept/reject/modify individual proposals,  and only approved changes propagate to
    the knowledge base. This maintains  human authority while leveraging automated proposal generation.\n\n\n**When to use:**
    Apply when automated systems generate modifications to persistent knowledge  structures, and when the cost of incorrect
    modifications exceeds the cost  of human review. Essential for knowledge bases where coherence and  authority matter.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: reformulation-as-reconciliation
  name: Reformulation-as-Reconciliation
  summary: Using LLM to suggest how elements could be rephrased to enable new relationships.
  description: "Using LLM to suggest how elements could be rephrased to enable new relationships.\n\nA technique where, instead
    of only matching elements as they exist, an  LLM proposes how elements could be reformulated to create valid  relationships.
    The LLM examines the semantic distance between elements  and suggests minimal modifications that would make connection
    meaningful.  Crucially, it generates multiple reformulation options rather than a  single recommendation.\n\n\n**When
    to use:** Apply when knowledge elements are close enough to relate but their current  formulations create friction, and
    when preserving the underlying meaning  while enabling connection is more valuable than maintaining exact wording.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: multi-tier-matching-pipeline
  name: Multi-Tier Matching Pipeline
  summary: Graduated approach from direct matching to modified matching to user acceptance.
  description: "Graduated approach from direct matching to modified matching to user acceptance.\n\nA processing pipeline
    that attempts matches at multiple tiers of intervention:  first seeking direct connections with no modifications, then
    proposing  single-element modifications, then bilateral modifications, and finally  presenting all viable options for
    user selection. Each tier represents  increased intervention surface and is attempted only if prior tiers  prove insufficient.\n\
    \n\n**When to use:** Apply when reconciling knowledge elements where exact matches are preferred  but near-matches are
    acceptable with modification, and where the cost of  modification should be proportional to matching difficulty.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: stray-element-detection
  name: Stray Element Detection
  summary: Programmatically identify elements that lack required relationship connections.
  description: "Programmatically identify elements that lack required relationship connections.\n\nA pattern for finding \"\
    orphaned\" elements in knowledge graphs—elements  that should have relationships but don't. In this case, principles without\
    \  feature connections and features without principle connections. The  detection is structural (graph traversal) rather
    than semantic, identifying  absence through query rather than judgment.\n\n\n**When to use:** Apply when building knowledge
    management systems where relationships between  element types are expected but not enforced, and you want to surface gaps\
    \  for remediation rather than letting them silently accumulate.\n"
  project: prompt-extraction
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: new-feature-test-123
  name: New Feature Test 123
  summary: Testing ID gen
  description: "Testing ID gen\n\nShould work now"
  project: test
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: feat_test_feature_abc_041816
  name: Test Feature ABC
  summary: A test feature
  description: For testing
  project: test
  confidence: 0.75
  status: draft
  principles: []
  grounding_count: 0
- id: provenance-attached-writing-context
  name: Provenance-Attached Writing Context
  summary: Food for thought items carry provenance tracking that attaches as context during the writing stage.
  description: The system tracks where each food for thought item originated and how it was integrated into the outline.
    During writing execution, this provenance attaches as context, enabling the generation to draw on the original 
    sources and reasoning that led to each element. This creates traceability from final prose back to corpus origins.
  project: dictation-features
  confidence: 0.84
  status: draft
  principles:
  - principle_id: prn_bespoke_contextual
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_generative_personalization
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_process_as_data
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_structured_integration
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: abundance-carrying-with-deferred-closure
  name: Abundance Carrying with Deferred Closure
  summary: For factual information, the system maintains multiple possibilities throughout the process, deferring 
    selection until writing.
  description: Rather than closing prematurely on which facts to use, the system carries abundance—maintaining multiple 
    possibilities for factual information until the end. Selection happens based on the role facts play at writing time.
    Users focus on the vector (direction and function) rather than particularities. This contrasts with evaluative 
    claims that do require earlier commitment.
  project: dictation-features
  confidence: 0.87
  status: draft
  principles:
  - principle_id: prn_deferred_selection
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_epistemic_weight_routing
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_optionality_preservation
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_adaptive_termination
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_possibility_space
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: plain-language-direction-with-llm-classification
  name: Plain Language Direction with LLM Classification
  summary: Users express intentions in natural language while LLMs handle classification into logical outline structures
    and pattern-matching.
  description: Instead of requiring users to classify how claims fit the logical outline, users describe broader 
    directions in plain language. LLMs perform the classification, pattern-matching what facts or claims are needed to 
    fulfill stated functions. Users say 'I would like to illustrate this' and the system surfaces what's available, or 
    coaching indicates 'There are gaps your outline that best exemplars would normally feature.'
  project: dictation-features
  confidence: 0.88
  status: draft
  principles:
  - principle_id: prn_genre_as_scaffold
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_thinking_environments
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_anthropologist_role
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_hegelian_abstraction
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_interactive_cognition
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: choice-creation-through-analysis-cycles
  name: Choice Creation Through Analysis Cycles
  summary: The system recognizes that clean choices don't exist at the start but emerge through extraction, re-analysis,
    and understanding implications.
  description: Rather than presuming available material choices from the start, the system manages the gradual emergence
    of choices through work cycles. Initially there are no clean choices—they are created by analyzing corpora for 
    materials, organizing by genre function expectations, and reviewing fit with both genre best practices and the 
    central argument. Only at the end of the cycle do genuine choices become available.
  project: dictation-features
  confidence: 0.89
  status: draft
  principles:
  - principle_id: prn_schema_as_hypothesis
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_abductive_logic
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_emergent_choice
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: pre-curated-cluster-streams-with-bundle-selection
  name: Pre-Curated Cluster Streams with Bundle Selection
  summary: Curatorial agents pre-curate multiple streams of fact clusters, allowing users to select at the bundle level 
    rather than evaluating individual items.
  description: Based on best practices and functional requirements, curatorial agents pre-curate three (or more) streams
    of clustered facts. Users choose among these curated bundles rather than individually reviewing all items. This 
    enables steering by 'direction of travel' within broader teleology—the rest can be fetched and curated later, even 
    during writing.
  project: dictation-features
  confidence: 0.88
  status: draft
  principles:
  - principle_id: prn_optionality_preservation
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_deferred_selection
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_front_load_decisions
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_possibility_space
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_hegelian_abstraction
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_epistemic_weight_routing
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: logical-rhetorical-linkage-tracking
  name: Logical-Rhetorical Linkage Tracking
  summary: The system maintains explicit links between logical propositions and rhetorical requirements, tracking gaps 
    and triggering targeted extraction.
  description: For every genre archetype, the system maps what rhetorical propositions require what logical 
    propositions. This creates a benchmark linking logical and rhetorical outlines. The system tracks what's amiss—where
    rhetorical needs lack logical support—and pushes for targeted extraction to fill gaps. Materials may serve different
    functions across the two outlines (evidence, transition, hooks).
  project: dictation-features
  confidence: 0.86
  status: draft
  principles:
  - principle_id: prn_dual_outline_constraint
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_cybernetic_correction
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_abstraction_independence
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_genre_as_scaffold
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: food-for-thought-integration-pathways
  name: Food for Thought Integration Pathways
  summary: 'Approved propositions integrate into the outline through explicit pathways: fold into existing argument, elevate
    to claim, or generate new branch.'
  description: "When a user approves a food for thought item, the system facilitates choosing an integration pathway: folding
    it into an existing argument (enrichment), using it to generate a higher unit of analysis (claim), or creating an entirely
    new argument branch (expansion). LLMs facilitate this choice by presenting options appropriate to the proposition's nature."
  project: dictation-features
  confidence: 0.87
  status: draft
  principles:
  - principle_id: prn_controlled_propagation
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_llm_first_creative
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_structured_integration
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: cross-pollination-proposition-generation
  name: Cross-Pollination Proposition Generation
  summary: The system generates propositions as discrete units of cross-pollination between user hypothesis and corpus 
    content.
  description: Cross-pollination occurs between the user's current argument/thesis and corpus materials, generating 
    'propositions' (food for thought) as individual reviewable units. Each proposition pre-generates a potential path 
    for the argument. Users review whether propositions advance their argument in depth (deepening existing claims) or 
    breadth (expanding into new territory).
  project: dictation-features
  confidence: 0.91
  status: draft
  principles:
  - principle_id: prn_deferred_selection
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_tacit_to_explicit
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_epistemic_friction
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_emergent_choice
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: role-based-fact-mobilization-on-demand
  name: Role-Based Fact Mobilization On-Demand
  summary: Facts are extracted comprehensively but mobilized on-demand based on the functional role they need to 
    fulfill.
  description: "Rather than pre-selecting facts during curation, the system extracts all available facts and determines which
    to mobilize based on declared function. The function defines what's needed: 'To illustrate ideas, how life shaped ideas,
    or introduce someone unknown? Depending on function, the facts we extract will differ.' Even at writing stage, additional
    facts can be fetched for anecdotes."
  project: dictation-features
  confidence: 0.89
  status: draft
  principles:
  - principle_id: prn_registry_exposed_to_llm
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_machine_legible_affordances
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_optionality_preservation
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_deferred_selection
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_compensate_llm_limits
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_possibility_space
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: genre-archetype-function-mapping
  name: Genre Archetype Function Mapping
  summary: Each genre archetype has a defined typology of logical functions and rhetorical expectations that guide 
    extraction and review.
  description: For each genre (intellectual profile, ideas essay, etc.), the system maintains a breakdown of expected 
    functions and logical clusters. Review happens based on function ('This looks like a good element for our 
    contextualization function'). A Perry Anderson piece requires certain rhetorical propositions which require certain 
    logical propositions—this mapping guides what to extract and identifies gaps.
  project: dictation-features
  confidence: 0.88
  status: draft
  principles:
  - principle_id: prn_paradigm_embodiment
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_synthesis_first_bootstrap
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_genre_as_scaffold
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_dual_outline_constraint
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_perspective_as_structure
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: tiered-material-classification-with-differential-review
  name: Tiered Material Classification with Differential Review
  summary: Materials are classified into ideational claims requiring human review versus factual data delegated to LLM 
    curation.
  description: The system separates 'critical, evaluative, provocative, contrarian units of food for thought from 
    cross-pollination' that require careful human review from 'factual claims from corpora' that can be delegated to 
    curatorial agents for clustering and grouping. Ideational claims shape the logical outline directly; factual data is
    mobilized on-demand based on functional requirements without individual review.
  project: dictation-features
  confidence: 0.91
  status: draft
  principles:
  - principle_id: prn_epistemic_weight_routing
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_human_authority_gate
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_resource_proportionality
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_hegelian_abstraction
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: versioned-questionnaire-regeneration-pipeline
  name: Versioned Questionnaire Regeneration Pipeline
  summary: Each outline version generates new questionnaires, with explicit tracking of which previous answers to 
    revise, retain, or retire.
  description: When upgrading from Version N to Version N+1 of an outline, the system sends all previous questionnaire 
    answers alongside both outline versions to generate new questions and answers. It explicitly identifies which 
    existing answers remain valid, which need revision, and which are no longer relevant. By Version 5, the accumulated 
    corpus contains all current answers plus version-specific refinements.
  project: dictation-features
  confidence: 0.9
  status: draft
  principles:
  - principle_id: prn_cascade_containment
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_process_as_data
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_logical_coherence
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_extraction_permanence_tiers
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_lens_dependent_extraction
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: eternal-ephemeral-extraction-dichotomy
  name: Eternal-Ephemeral Extraction Dichotomy
  summary: Corpus analysis separates fixed questions asked of all inputs from project-specific questions that evolve 
    with outline versions.
  description: 'The system maintains two extraction dimensions: eternal (fixed questions about main argument, concepts, dialectical
    tensions—shared across projects and extracted once to persist indefinitely) and ephemeral (project- and outline-version-specific
    questions that regenerate as the outline evolves). When upgrading outline versions, the ephemeral questionnaire regenerates
    while eternal answers provide stable context.'
  project: dictation-features
  confidence: 0.93
  status: draft
  principles:
  - principle_id: prn_fixed_foundation
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_lens_dependent_extraction
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_extraction_permanence_tiers
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_event_driven_refinement
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: outline-version-dependent-corpus-interrogation
  name: Outline-Version-Dependent Corpus Interrogation
  summary: The same corpora produces different food for thought based on the current version of the logical and 
    functional outline.
  description: As users refine their logical and functional outline from Version 1 to Version N, the system regenerates 
    'food for thought' by re-interrogating the same corpora with evolved questions. The outline acts as a lens that 
    determines what becomes visible and extractable from source materials. Version 1 may surface certain 
    cross-pollinations while Version 5 reveals entirely different propositions from identical inputs.
  project: dictation-features
  confidence: 0.92
  status: draft
  principles:
  - principle_id: prn_abductive_logic
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_co_evolution
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_extraction_permanence_tiers
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_lens_dependent_extraction
    how_embodied: ''
    confidence: 0.8
  - principle_id: prn_living_artifacts
    how_embodied: ''
    confidence: 0.8
  grounding_count: 0
- id: ai-indispensability-declaration
  name: AI Indispensability Declaration
  summary: The system explicitly declares that AI is 'completely indispensable' and that future redesigns must preserve 
    LLM composition, execution, and evaluation of queries.
  description: 'The commentary makes an explicit architectural commitment: AI enables the restructuring of processes to ask
    high-impact questions early, and LLMs are essential for formulating, executing, and monitoring queries. Any redesign must
    preserve this fundamental role.'
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_fixed_foundation
    how_embodied: LLM role declared as fixed architectural constraint
    confidence: 0.75
  - principle_id: prn_llm_first_creative
    how_embodied: Explicit declaration that LLMs are primary rather than supplementary
    confidence: 0.75
  grounding_count: 0
- id: exhaustive-effector-audit
  name: Exhaustive Effector Audit
  summary: The system requires periodic audits to ensure all technical capabilities of Google Scholar are captured in 
    the Effector registry.
  description: The commentary identifies that current Effectors are not exhaustive—capabilities like law review 
    filtering or site-specific searches are unused. This implies a design commitment to systematically auditing 
    available technical capabilities and ensuring the registry captures them all.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_compensate_llm_limits
    how_embodied: Expanding Effectors increases non-LLM resources available for compensation
    confidence: 0.75
  - principle_id: prn_possibility_space
    how_embodied: Audits ensure the full possibility space of technical capabilities is available
    confidence: 0.75
  grounding_count: 0
- id: direct-registry-modification-pipeline
  name: Direct Registry Modification Pipeline
  summary: The envisioned system shortens the path from meta-learning suggestions to registry modifications, enabling 
    feedback to directly restructure operational schemas.
  description: The commentary describes a desired architecture where suggestions from meta-learning can be clustered by 
    AI, reviewed by users (accept/reject/refine), and translated directly into registry modifications by LLMs. The goal 
    is to eliminate intermediary steps between insight and implementation.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cybernetic_correction
    how_embodied: Direct modification enables faster correction cycles
    confidence: 0.75
  - principle_id: prn_hegelian_abstraction
    how_embodied: Human work shifts to abstract review while LLMs handle implementation
    confidence: 0.75
  grounding_count: 0
- id: exclusion-based-discovery
  name: Exclusion-Based Discovery
  summary: The system uses exclude operators to filter out known entities (authors, sources) in order to surface 
    genuinely novel material.
  description: A key tactical pattern is using exclusion to enable discovery—by explicitly excluding known authors and 
    sources, searches can surface novel material that would otherwise be buried beneath landmark results. This combines 
    with date filtering to target recent work by unknown authors.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_compensate_llm_limits
    how_embodied: Using exclusion to compensate for LLM's tendency to know only landmarks
    confidence: 0.75
  - principle_id: prn_epistemic_friction
    how_embodied: Deliberately creating conditions for unfamiliar material to surface
    confidence: 0.75
  grounding_count: 0
- id: meta-learning-module
  name: Meta-Learning Module
  summary: A learning module analyzes LLM responses to think through what new strategies or Effector combinations would 
    be possible, feeding improvements back into the system.
  description: The system includes a meta-learning component that analyzes feedback from operations to suggest 
    improvements. While Effectors themselves are fixed, the ways they combine with strategies is not. The module aims to
    identify patterns in results that suggest new tactical combinations or registry refinements.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cybernetic_correction
    how_embodied: System-level self-reflection and adjustment
    confidence: 0.75
  - principle_id: prn_abductive_logic
    how_embodied: Using operational data to refine system theory
    confidence: 0.75
  grounding_count: 0
- id: llm-batch-ranking
  name: LLM Batch Ranking
  summary: Final ranking of harvested papers occurs in batches (up to 150-200) through LLM evaluation, selecting top 
    results across all clusters.
  description: The final phase involves LLM-based ranking of large batches of papers—potentially 150-200 at a time. 
    Papers are evaluated for relevance to the research goal, with a selection process that narrows to a final set (e.g.,
    200 pieces) across all clusters. This leverages LLM capacity for rapid relevance assessment.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_llm_first_creative
    how_embodied: Using LLM judgment for relevance evaluation
    confidence: 0.75
  - principle_id: prn_chunking
    how_embodied: Batch-based ranking as chunked evaluation process
    confidence: 0.75
  grounding_count: 0
- id: trans-cluster-operations
  name: Trans-Cluster Operations
  summary: Operations that span across all clusters after individual cluster execution, enabling system-wide analysis 
    and citation harvesting for top results.
  description: After all clusters complete their four phases, the system performs operations across the entire result 
    set—finding the most promising works across all clusters and doing deep citation work on them. This enables insights
    that only emerge from seeing results holistically rather than cluster-by-cluster.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_process_determinism
    how_embodied: Trans-cluster operations are a defined phase building on cluster outputs
    confidence: 0.75
  - principle_id: prn_hegelian_abstraction
    how_embodied: Moving from individual clusters to holistic view represents abstraction level shift
    confidence: 0.75
  grounding_count: 0
- id: family-strategies-system
  name: Family Strategies System
  summary: Content and semantics-based search techniques—ways of combining semantic units like thinkers with 
    concepts—that represent cultivated research best practices.
  description: Family Strategies are distinct from Effectors in being semantic rather than technical. They describe 
    'techniques and best practices' for combining semantic units in queries—pairing thinker names with concept names, 
    for instance. They represent accumulated research craft knowledge encoded into reusable patterns.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_tacit_to_explicit
    how_embodied: Cultivated craft knowledge rendered explicit as named strategies
    confidence: 0.75
  - principle_id: prn_fixed_foundation
    how_embodied: Strategies form a stable repertoire of approaches
    confidence: 0.75
  grounding_count: 0
- id: effectors-system
  name: Effectors System
  summary: Procedural operators that leverage Google Scholar's technical capabilities—date exclusion, parameter 
    filtering, source restriction, exclude operators—to optimize search mechanics.
  description: Effectors are defined as 'procedural and operational' mechanisms that exploit the technical capabilities 
    of Google Scholar's query system. They include date restrictions, exclude operators, source filtering, and other 
    mechanical optimizations. They are distinct from semantic strategies and form a fixed registry that LLMs can draw 
    upon.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_compensate_llm_limits
    how_embodied: Technical operations provide non-LLM resources to fill knowledge gaps
    confidence: 0.75
  - principle_id: prn_fixed_foundation
    how_embodied: Effectors form a fixed registry—stable ground for flexible strategies
    confidence: 0.75
  grounding_count: 0
- id: mid-card-evaluation-and-pivot
  name: Mid-Card Evaluation and Pivot
  summary: At the midpoint of a Card's budget, the system evaluates whether results are satisfactory and can pivot to 
    alternative strategies if not.
  description: The system includes explicit checkpoints for mid-course evaluation. If half the budget is spent and 
    results are disappointing, the system can switch strategies, launch a different Card, or abandon the current 
    approach. This includes 'abandoned query checks' to decide whether to use partial results or redo queries.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cybernetic_correction
    how_embodied: Explicit checkpoint for course correction based on performance
    confidence: 0.75
  - principle_id: prn_process_determinism
    how_embodied: Evaluation points are deterministic even if outcomes are not
    confidence: 0.75
  grounding_count: 0
- id: real-time-query-evaluation-and-correction
  name: Real-Time Query Evaluation and Correction
  summary: LLMs evaluate query results in real-time and draw on registries of possible actions to formulate improved 
    subsequent queries.
  description: After each query executes, the system evaluates results and decides how to improve the next query. LLMs 
    can draw on a Registry of Effectors, Family Strategies, and AI Operations to formulate adjustments. This enables 
    flexible strategies that course-correct based on actual results rather than predetermined paths.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_abductive_logic
    how_embodied: Using data from queries to refine subsequent query formulation
    confidence: 0.75
  - principle_id: prn_llm_first_creative
    how_embodied: LLM evaluation enables non-deterministic adaptation
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Direct implementation of self-checking and course correction at every stage
    confidence: 0.75
  grounding_count: 0
- id: cards-as-tactical-units
  name: Cards as Tactical Units
  summary: Within the discovery phase, Cards function as 'sub-sub-strategies' with individual budgets, specific search 
    tactics, and evaluation checkpoints.
  description: Cards represent the finest granularity of strategic decomposition—individual tactical approaches within 
    the discovery phase. Each Card has a budget allocation, a specific search strategy (e.g., 'get authors from last 
    five years using key terms in title'), and is subject to query-level evaluation. Cards can be abandoned 
    mid-execution if results are disappointing.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_chunking
    how_embodied: Cards are the smallest discrete chunks of the search process
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Card-level granularity enables fine-grained course correction
    confidence: 0.75
  grounding_count: 0
- id: anti-recency-discovery-phase
  name: Anti-Recency Discovery Phase
  summary: Phase 1 deliberately fights LLM memory limitations through exclusion-based searches that target recent work 
    missing from training data.
  description: The discovery phase has an explicit goal of finding authors, sources, and vocabulary from the last five 
    years that are likely missing from LLM memory due to training cutoffs. It uses exclusion operators to remove known 
    authors while filtering to recent dates, creating a deliberate strategy to surface novel recent work.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_compensate_llm_limits
    how_embodied: Direct manifestation of actively compensating for LLM cutoff limitations
    confidence: 0.75
  - principle_id: prn_abductive_logic
    how_embodied: Discovery phase gathers new data to refine the knowledge base
    confidence: 0.75
  grounding_count: 0
- id: llm-memory-extraction-phase
  name: LLM Memory Extraction Phase
  summary: Phase 0 pulls landmark texts, authors, publications, and terms from LLM memory to establish a baseline of 
    known knowledge before seeking novelty.
  description: Before active searching, the system extracts what the LLM already 'knows' about the field—landmark works,
    key figures, important publications. This establishes a baseline that enables the subsequent discovery phase to 
    identify truly novel material by excluding known landmarks.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_compensate_llm_limits
    how_embodied: Extracting memory creates the baseline needed to compensate for cutoff dates
    confidence: 0.75
  - principle_id: prn_llm_first_creative
    how_embodied: Using LLM knowledge generation before external searches
    confidence: 0.75
  grounding_count: 0
- id: four-phase-cluster-execution
  name: Four-Phase Cluster Execution
  summary: 'Each cluster executes through four distinct phases: Remembering (Phase 0), Discovery (Phase 1), Execution (Phase
    2), and Citations (Phase 3).'
  description: 'The system structures cluster execution as a four-phase process: first pulling landmarks from LLM memory,
    then actively discovering recent work not in that memory, then executing large-scale searches with all gathered terms,
    and finally looking up citations for promising results. This creates a systematic flow from knowledge baseline through
    expansion to depth.'
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_chunking
    how_embodied: Breaking execution into defined phases with distinct purposes
    confidence: 0.75
  - principle_id: prn_process_determinism
    how_embodied: Phases chain together building on each other's work
    confidence: 0.75
  grounding_count: 0
- id: user-term-engagement-interface
  name: User Term Engagement Interface
  summary: Users can edit, add, delete, and tinker with terms and clusters before execution begins, enabling substantive
    engagement with the search strategy.
  description: Before execution, users are presented with generated strategies, clusters, and terms that they can 
    modify. They can delete unwanted elements, add new ones, exclude publications or authors, and add terms in other 
    languages. The system is designed to encourage early engagement because quality depends on initial term accuracy.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_interactive_cognition
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_anthropologist_role
    how_embodied: Structured interface helps externalize tacit knowledge about relevant terms
    confidence: 0.75
  - principle_id: prn_thinking_environments
    how_embodied: Interface designed to solicit feedback and enable refinement
    confidence: 0.75
  grounding_count: 0
- id: fixed-and-flexible-categories
  name: Fixed and Flexible Categories
  summary: The system maintains both universal categories (Concepts, Thinkers) and field-specific flexible categories 
    (Events, Battles, Party Congresses) that adapt to the research domain.
  description: Within term categories, some elements are fixed across all research contexts—like Concepts and 
    Thinkers—while others are generated based on the specific field being researched. This creates a scaffold that is 
    partly stable and partly adaptive to the domain's particular taxonomic logic.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_fixed_foundation
    how_embodied: Direct manifestation of keeping certain elements rigid while others flex
    confidence: 0.75
  - principle_id: prn_bespoke_contextual
    how_embodied: Flexible categories enable domain-appropriate customization
    confidence: 0.75
  - principle_id: prn_generative_personalization
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: hierarchical-strategy-structure
  name: Hierarchical Strategy Structure
  summary: 'Research execution is organized hierarchically: Strategies contain Clusters (sub-strategies), which contain categorized
    terms including Concepts, Thinkers, and field-specific elements.'
  description: 'The system organizes research through multiple nested levels: strategies at the top, clusters as sub-strategies
    within them, and various categories of terms within clusters. This creates a clear hierarchy from broad approach down
    to specific search elements, enabling both strategic overview and granular control.'
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_chunking
    how_embodied: Breaking down the research process into nested smaller chunks
    confidence: 0.75
  - principle_id: prn_hegelian_abstraction
    how_embodied: Multiple levels of abstraction from concrete terms to abstract strategies
    confidence: 0.75
  grounding_count: 0
- id: multi-strategy-research-slicing
  name: Multi-Strategy Research Slicing
  summary: The system presents multiple strategic approaches to 'slice the research cake'—chronological, analogical, 
    conceptual, or eclectic—acknowledging that research admits many valid entry points.
  description: Rather than imposing a single research methodology, the system pre-generates what seem like the most 
    likely strategies and entry points, presenting them to users. This reflects recognition that research projects can 
    be approached through different lenses and that the choice of lens should be explicit rather than assumed.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_perspective_as_structure
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_paradigm_embodiment
    how_embodied: Different strategies embody different paradigmatic orientations to research
    confidence: 0.75
  - principle_id: prn_possibility_space
    how_embodied: Presenting multiple strategic options rather than forcing single approach
    confidence: 0.75
  grounding_count: 0
- id: llm-generated-dynamic-questions
  name: LLM-Generated Dynamic Questions
  summary: Follow-up questions are generated by LLMs based on research mode and user answers, creating highly customized
    interrogation.
  description: After the initial mode selection, the system generates 5-6 follow-up questions determined by LLM prompts 
    that depend on both the chosen research mode and previous answers. These questions are pre-generated in real-time, 
    though the commentary notes potential for even more dynamic generation where questions are formulated while users 
    answer previous ones.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_generative_personalization
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_llm_first_creative
    how_embodied: Using LLM non-determinism for creative question generation rather than fixed algorithmic questioning
    confidence: 0.75
  - principle_id: prn_bespoke_contextual
    how_embodied: Questions are personalized to the specific research context
    confidence: 0.75
  - principle_id: prn_anthropologist_role
    how_embodied: LLM-generated questions operationalize the anthropologist function of guided elicitation
    confidence: 0.75
  grounding_count: 0
- id: front-loaded-critical-questioning
  name: Front-Loaded Critical Questioning
  summary: The system prioritizes getting the most important information first, recognizing that early answers create 
    path dependencies for all subsequent interactions.
  description: The system is designed to ask 'big questions first' because knowing critical information early enables 
    proper structuring of all follow-up questions. This acknowledges that there are path dependencies—what users answer 
    early determines what questions make sense later.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_front_load_decisions
    how_embodied: Created by refactoring engine
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: Breaking down into stages where early chunks inform later ones
    confidence: 0.75
  - principle_id: prn_process_determinism
    how_embodied: Chaining processes where early outputs structure later inputs
    confidence: 0.75
  grounding_count: 0
- id: research-mode-pre-selection
  name: Research Mode Pre-Selection
  summary: Users must choose their research mode at the beginning, forcing them to confront what they're truly seeking 
    before any queries begin.
  description: The system requires users to select a research mode upfront, pre-structuring choices to help users grasp 
    their ideal output. This forces early commitment that enables highly customized subsequent questioning. The modes 
    include options like single-query focus or Venn diagram overlapping disciplines.
  project: GS HARVESTER
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_intellectual_profile
    how_embodied: Early mode selection builds the intellectual profile that enables subsequent pattern-matching
    confidence: 0.75
  - principle_id: prn_tacit_to_explicit
    how_embodied: Renders implicit research goals explicit before committing to queries
    confidence: 0.75
  - principle_id: prn_anthropologist_role
    how_embodied: Structured process to help users externalize tacit knowledge about what they actually want
    confidence: 0.75
  grounding_count: 0
- id: spiral-development-mechanism
  name: Spiral Development Mechanism
  summary: Schema interrogates concrete, concrete reshapes schema, refined schema reveals new aspects previously 
    invisible.
  description: "Not merely adding examples to a schema, but a genuine spiral: the schema provides a lens for examining sources,
    sources reveal schema inadequacies, the refined schema enables seeing new patterns in the same sources. Each complete
    cycle produces a schema that is both more abstract (more universal) and more concrete (more determinate).\n"
  project: concrete-abstractor
  confidence: 0.9
  status: draft
  principles:
  - principle_id: prn_epistemic_friction
    how_embodied: Each turn of the spiral requires confrontation with resistance
    confidence: 0.75
  - principle_id: prn_abductive_logic
    how_embodied: The spiral IS the theory-data movement made concrete
    confidence: 0.75
  grounding_count: 0
- id: schema-versioning-evolution-tracking
  name: Schema Versioning and Evolution Tracking
  summary: Maintain version control or diff-based tracking of how schemas change through refinement iterations.
  description: "As schemas evolve through multiple refinement passes, the system should track what changed, when, and why.
    This enables rollback, comparison of schema versions, understanding of schema development trajectory, and auditing of
    refinement decisions.\n"
  project: concrete-abstractor
  confidence: 0.85
  status: draft
  principles:
  - principle_id: prn_tacit_to_explicit
    how_embodied: Version history makes evolution trajectory explicit
    confidence: 0.75
  - principle_id: prn_chunking
    how_embodied: Each version is a chunk in the evolution timeline
    confidence: 0.75
  grounding_count: 0
- id: resistance-based-refinement
  name: Resistance-Based Refinement
  summary: Use the schema's failure to categorize source material as the generative signal for improvement.
  description: "The tool specifically looks for where the schema fails to account for what's in the text—where reality resists
    categorization. These points of failure become the basis for refinement proposals. The friction between abstract schema
    and concrete instance is not a bug but the primary mechanism of improvement.\n"
  project: concrete-abstractor
  confidence: 0.9
  status: draft
  principles:
  - principle_id: prn_abductive_logic
    how_embodied: Data resistance triggers theory revision
    confidence: 0.75
  - principle_id: prn_epistemic_friction
    how_embodied: Friction between schema and source is the generative mechanism
    confidence: 0.75
  grounding_count: 0
- id: proposal-interdependency-management
  name: Proposal Interdependency Management
  summary: Handle cases where accepting one refinement proposal changes the context for evaluating other proposals.
  description: "When multiple proposals are generated from the same analysis pass, they may interact—accepting one proposal
    might make another irrelevant, contradictory, or more/less important. The system needs to either batch proposals with
    dependency analysis or present them sequentially with re-evaluation after each decision.\n"
  project: concrete-abstractor
  confidence: 0.7
  status: draft
  principles:
  - principle_id: prn_chunking
    how_embodied: Dependency tracking adds complexity to chunked processing
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Re-evaluation after each decision is a correction mechanism
    confidence: 0.75
  grounding_count: 0
- id: iterative-schema-enrichment
  name: Iterative Schema Enrichment
  summary: Systematically refine provisional schemas by confronting them with source material through multiple passes.
  description: "Takes skeletal schemas generated from synthesis and enriches them through iterative re-engagement with original
    sources. Each iteration identifies where the schema succeeds or fails to capture reality, generates refinement proposals,
    and updates the schema based on human-approved changes. The process continues until convergence or human termination.\n"
  project: concrete-abstractor
  confidence: 0.95
  status: draft
  principles:
  - principle_id: prn_cybernetic_correction
    how_embodied: Feedback at every iteration drives improvement
    confidence: 0.75
  - principle_id: prn_chunking
    how_embodied: Each pass is a bounded, inspectable step
    confidence: 0.75
  - principle_id: prn_abductive_logic
    how_embodied: The entire refinement cycle IS the theory-data spiral
    confidence: 0.75
  grounding_count: 0
- id: human-in-loop-proposal-review
  name: Human-in-Loop Proposal Review
  summary: LLM generates refinement proposals; humans make final decisions on schema modifications.
  description: "The system analyzes schema-source mismatches and generates specific proposals (split types, merge types, new
    dimensions, etc.) but does not autonomously modify the schema. Instead, it presents proposals for rapid human review with
    approve/reject/modify options. Early decisions influence subsequent proposals through feedback learning.\n"
  project: concrete-abstractor
  confidence: 0.9
  status: draft
  principles:
  - principle_id: prn_intellectual_profile
    how_embodied: Feedback learning builds model of reviewer preferences
    confidence: 0.75
  - principle_id: prn_llm_first_creative
    how_embodied: LLM handles interpretive work, not categorical authority
    confidence: 0.75
  - principle_id: prn_compensate_llm_limits
    how_embodied: LLM proposes, human decides, database stores
    confidence: 0.75
  grounding_count: 0
- id: cross-genre-cascade-management
  name: Cross-Genre Cascade Management
  summary: Handle cascading refinements when one genre's schema changes affect other genres' schemas.
  description: "When this tool refines a genre's schema, it may trigger re-evaluation of other genres that share abstractions
    or dimensions. The system needs to manage these cascades to prevent infinite loops while maintaining full dynamism—allowing
    legitimate propagation of insights across genres without runaway recursion.\n"
  project: concrete-abstractor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_epistemic_friction
    how_embodied: Cross-genre friction reveals shared inadequacies
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Cascades are system-level feedback propagation
    confidence: 0.75
  grounding_count: 0
- id: cost-aware-processing-strategy
  name: Cost-Aware Processing Strategy
  summary: Balance thoroughness of refinement with practical cost constraints through tiered processing and sampling.
  description: "Full iterative refinement across large corpora using premium LLMs could be expensive. The system should support
    tiered processing (cheaper models for initial passes, premium models for refinement) and intelligent sampling strategies
    to maximize insight per dollar spent.\n"
  project: concrete-abstractor
  confidence: 0.8
  status: draft
  principles:
  - principle_id: prn_chunking
    how_embodied: Chunking enables selective high-investment processing
    confidence: 0.75
  - principle_id: prn_compensate_llm_limits
    how_embodied: Different models for different tasks based on capability needs
    confidence: 0.75
  grounding_count: 0
- id: convergence-detection
  name: Convergence Detection
  summary: Determine when iterative refinement has reached diminishing returns and should terminate.
  description: "The system needs mechanisms to detect when the schema has stabilized—when additional passes through source
    material produce few or no refinement proposals, or when proposals become increasingly minor. This could involve schema
    stability metrics, proposal frequency tracking, or human judgment about when to stop.\n"
  project: concrete-abstractor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_chunking
    how_embodied: Convergence is measured at chunk boundaries
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Meta-level feedback about the process itself
    confidence: 0.75
  grounding_count: 0
- id: reconciliation-handoff-protocol
  name: Reconciliation Handoff Protocol
  summary: Determine when conflicting proposals should be handled internally versus delegated to Cross-Advisor tool.
  description: "When multiple source files produce conflicting refinement proposals, the system needs logic for deciding whether
    to reconcile internally (e.g., through confidence scoring or majority voting) or escalate to the Cross-Advisor tool for
    explicit reconciliation of divergent perspectives.\n"
  project: concrete-abstractor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_compensate_llm_limits
    how_embodied: Escalation compensates for single-model limitations
    confidence: 0.75
  - principle_id: prn_epistemic_friction
    how_embodied: Genuine conflicts are epistemically valuable friction
    confidence: 0.75
  - principle_id: prn_cross_model_examination
    how_embodied: Cross-Advisor leverages model diversity for reconciliation
    confidence: 0.75
  - principle_id: prn_divergence_as_signal
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: trigger-based-invocation
  name: Trigger-Based Invocation
  summary: Automatically initiate schema refinement when specific events occur across the system.
  description: "The tool can be triggered by multiple events: post-synthesis completion, new specimen added to corpus, another
    genre's schema modified (cross-genre trigger), scheduled periodic refinement, or manual invocation. This enables dynamic
    schema evolution in response to system changes.\n"
  project: concrete-abstractor
  confidence: 0.85
  status: draft
  principles:
  - principle_id: prn_abductive_logic
    how_embodied: New data triggers theory revision
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Triggers are environmental feedback signals
    confidence: 0.75
  grounding_count: 0
- id: probabilistic-regularity-assumption
  name: Probabilistic Regularity Assumption
  summary: The system assumes LLM responses follow probabilistic patterns that, while non-deterministic, are predictable
    enough to enable systematic cross-learning.
  description: The design rests on the assumption that even though LLM outputs are non-deterministic, they exhibit 
    sufficient regularity and pattern that exposing one model to another's reasoning provides genuine learning value. 
    The system treats LLM behavior as probabilistically structured rather than random.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_llm_first_creative
    how_embodied: Acknowledges non-determinism while still finding value in LLM outputs
    confidence: 0.75
  - principle_id: prn_process_determinism
    how_embodied: Justifies building deterministic processes around non-deterministic content
    confidence: 0.75
  grounding_count: 0
- id: accelerated-domain-modeling
  name: Accelerated Domain Modeling
  summary: The system rapidly builds a model of the problem domain in each LLM's context by exposing it to multiple 
    solution trajectories and critique patterns.
  description: Rather than having each model slowly discover domain patterns through its own trial and error, the system
    accelerates learning by showing each model how multiple approaches play out simultaneously. This compressed exposure
    to the 'possibility space' of solutions and their failure modes rapidly builds domain understanding.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_possibility_space
    how_embodied: Explores multiple solution trajectories to map the domain
    confidence: 0.75
  - principle_id: prn_abductive_logic
    how_embodied: Builds domain understanding through exposure to multiple data points
    confidence: 0.75
  grounding_count: 0
- id: stress-tested-robust-output
  name: Stress-Tested Robust Output
  summary: The final output has been subjected to multiple rounds of critique, defense, and cross-examination, making it
    more robust than single-model generation.
  description: The system's ultimate goal is producing outputs that have survived extensive scrutiny from multiple 
    perspectives. By the time a solution emerges, it has been challenged, defended, revised, and evaluated through 
    multiple lenses, making it more likely to withstand real-world implementation challenges.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_divergence_as_signal
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_cross_model_examination
    how_embodied: Cross-examination is the mechanism for stress-testing
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Multiple correction cycles improve output quality
    confidence: 0.75
  - principle_id: prn_epistemic_friction
    how_embodied: Friction through critique produces more robust outputs
    confidence: 0.75
  grounding_count: 0
- id: collaborative-implementation-planning
  name: Collaborative Implementation Planning
  summary: After selecting the winning solution, all three models collaborate to determine the specific implementation 
    approach.
  description: Once evaluation identifies the best solution, the system doesn't simply execute that model's 
    implementation plan. Instead, all three models contribute to figuring out how to implement the winning proposal, 
    potentially combining insights from different models' implementation strategies.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cross_model_examination
    how_embodied: Continues to leverage multiple model perspectives even after selection
    confidence: 0.75
  - principle_id: prn_divergence_as_signal
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_chunking
    how_embodied: Separates solution selection from implementation as distinct chunks
    confidence: 0.75
  grounding_count: 0
- id: blind-parallel-evaluation
  name: Blind Parallel Evaluation
  summary: An independent evaluation process where all three models rank the best shots without knowing which model 
    produced which solution.
  description: After best shots are formulated, all three models participate in evaluating the solutions, but the system
    conceals authorship to prevent bias. Each model ranks solutions based on merit alone, and these parallel evaluations
    determine the winning approach.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_epistemic_friction
    how_embodied: Different evaluation perspectives create productive friction in judgment
    confidence: 0.75
  - principle_id: prn_cross_model_examination
    how_embodied: Uses multiple models to evaluate outputs from multiple perspectives
    confidence: 0.75
  - principle_id: prn_divergence_as_signal
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  grounding_count: 0
- id: best-shot-formulation
  name: Best Shot Formulation
  summary: After multiple revision rounds, each model produces its final, best solution incorporating all learning from 
    the process.
  description: Following the iterative critique and observation cycles, each model synthesizes everything it has 
    learned—its own revisions, critiques received, and observations of peer approaches—into a single 'best shot' 
    solution. This represents the culmination of the learning process.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_process_determinism
    how_embodied: Defines a clear culmination point in the process flow
    confidence: 0.75
  - principle_id: prn_abductive_logic
    how_embodied: Synthesizes learning from iterative refinement into final output
    confidence: 0.75
  grounding_count: 0
- id: iterative-revision-rounds
  name: Iterative Revision Rounds
  summary: The system supports multiple rounds of solution refinement, with user-configurable workflow depth and 
    dependencies.
  description: Users can design workflows with varying numbers of revision cycles, where each round builds on previous 
    critiques and observations. The system provides flexibility in how many rounds to run while maintaining certain 
    dependencies like ranking steps that must occur after solution generation.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_abductive_logic
    how_embodied: Iterative refinement spirals toward better understanding
    confidence: 0.75
  - principle_id: prn_process_determinism
    how_embodied: Creates deterministic process structure while allowing non-deterministic content
    confidence: 0.75
  - principle_id: prn_cybernetic_correction
    how_embodied: Multiple rounds enable course correction at each stage
    confidence: 0.75
  - principle_id: prn_chunking
    how_embodied: Breaks the process into explicit stages with defined insertion points
    confidence: 0.75
  grounding_count: 0
- id: meta-exposure-to-peer-work
  name: Meta-Exposure to Peer Work
  summary: Each model sees not only critiques of its own work but also how other models solved the problem and what 
    critiques they received.
  description: Beyond receiving direct feedback, each model observes the complete problem-solving and critique cycles of
    the other models. Claude sees GPT's solution and the critiques GPT received, and Gemini's solution and its 
    critiques. This creates a meta-level learning environment where models learn from observing peer performance and 
    peer mistakes.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_divergence_as_signal
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_abductive_logic
    how_embodied: Multiple solution trajectories provide data for refining domain understanding
    confidence: 0.75
  - principle_id: prn_cross_model_examination
    how_embodied: Extends cross-examination to include observation of peer processes
    confidence: 0.75
  grounding_count: 0
- id: selective-critique-integration
  name: Selective Critique Integration
  summary: Models are instructed to discern and selectively accept or reject feedback rather than blindly incorporating 
    all suggestions.
  description: After receiving critiques, each model must actively evaluate the feedback and decide whether to defend 
    its original approach or accept modifications. The system explicitly instructs models to 'discern, not just blindly 
    accept everything,' treating them as agents with judgment rather than passive recipients of correction.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_cybernetic_correction
    how_embodied: Models self-correct through judgment rather than mechanical acceptance
    confidence: 0.75
  - principle_id: prn_epistemic_friction
    how_embodied: The resistance and selective acceptance creates productive friction
    confidence: 0.75
  grounding_count: 0
- id: multi-model-cross-examination
  name: Multi-Model Cross-Examination
  summary: Three different LLM models (Claude, Gemini, GPT) simultaneously solve the same problem and critique each 
    other's solutions.
  description: Each model generates its own solution to the user's problem, then receives critiques from the other two 
    models. This creates a triangulated approach where no single model's perspective dominates. The system orchestrates 
    parallel problem-solving followed by structured mutual critique.
  project: cross-advisor
  confidence: 0.75
  status: draft
  principles:
  - principle_id: prn_divergence_as_signal
    how_embodied: Re-linked from deprecated principle during refactoring
    confidence: 0.8
  - principle_id: prn_possibility_space
    how_embodied: Generates multiple solution approaches to explore the problem space
    confidence: 0.75
  - principle_id: prn_epistemic_friction
    how_embodied: Creates productive conflict between different model perspectives
    confidence: 0.75
  - principle_id: prn_cross_model_examination
    how_embodied: Directly implements cross-model examination as the core mechanism
    confidence: 0.75
  grounding_count: 0
